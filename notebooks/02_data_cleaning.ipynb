{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6216ce74",
   "metadata": {},
   "source": [
    "# üßπ √âtape 2 : Nettoyage et Pr√©paration des Donn√©es\n",
    "\n",
    "## üìã Objectifs de cette √©tape\n",
    "1. **Charger** les donn√©es explor√©es de l'√©tape 1\n",
    "2. **Traiter** les valeurs aberrantes intelligemment\n",
    "3. **Encoder** les variables cat√©gorielles\n",
    "4. **Ing√©nierie** des fonctionnalit√©s (feature engineering)\n",
    "5. **Diviser** les donn√©es (train/validation/test)\n",
    "6. **Normaliser** les donn√©es pour la mod√©lisation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c39fab2",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Configuration et Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c35a18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration termin√©e !\n",
      "üì¶ Pandas version: 2.3.2\n",
      "üìä NumPy version: 2.3.3\n",
      "ü§ñ Scikit-learn import√© avec succ√®s\n"
     ]
    }
   ],
   "source": [
    "# Configuration g√©n√©rale\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Manipulation des donn√©es\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Statistiques\n",
    "from scipy import stats\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Configuration des graphiques\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Param√®tres d'affichage\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "print(\"‚úÖ Configuration termin√©e !\")\n",
    "print(f\"üì¶ Pandas version: {pd.__version__}\")\n",
    "print(f\"üìä NumPy version: {np.__version__}\")\n",
    "print(f\"ü§ñ Scikit-learn import√© avec succ√®s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d381923",
   "metadata": {},
   "source": [
    "## üìä Chargement des Donn√©es Explor√©es\n",
    "\n",
    "Nous allons charger les donn√©es nettoy√©es de l'√©tape 1 d'exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4205ed29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Donn√©es charg√©es avec succ√®s !\n",
      "üìä Dataset original: (545, 14)\n",
      "üìä Dataset trait√©: (545, 13)\n",
      "\n",
      "üîç APER√áU DES DONN√âES CHARG√âES:\n",
      "   Shape: (545, 13)\n",
      "   Variables num√©riques: 13\n",
      "   Variables cat√©gorielles: 0\n",
      "   Valeurs manquantes: 0\n",
      "\n",
      "üìã VARIABLES DISPONIBLES:\n",
      "    1. price              (Num√©rique)\n",
      "    2. area               (Num√©rique)\n",
      "    3. bedrooms           (Num√©rique)\n",
      "    4. bathrooms          (Num√©rique)\n",
      "    5. stories            (Num√©rique)\n",
      "    6. mainroad           (Num√©rique)\n",
      "    7. guestroom          (Num√©rique)\n",
      "    8. basement           (Num√©rique)\n",
      "    9. hotwaterheating    (Num√©rique)\n",
      "   10. airconditioning    (Num√©rique)\n",
      "   11. parking            (Num√©rique)\n",
      "   12. prefarea           (Num√©rique)\n",
      "   13. furnishingstatus   (Num√©rique)\n"
     ]
    }
   ],
   "source": [
    "# 1. Chargement des donn√©es depuis l'√©tape 1\n",
    "processed_data_path = Path('../data/processed')\n",
    "\n",
    "# V√©rifier que les fichiers existent\n",
    "original_file = processed_data_path / 'housing_original.csv'\n",
    "processed_file = processed_data_path / 'housing_processed.csv'\n",
    "\n",
    "if original_file.exists() and processed_file.exists():\n",
    "    # Charger les deux versions\n",
    "    df_original = pd.read_csv(original_file)\n",
    "    df_processed = pd.read_csv(processed_file)\n",
    "    \n",
    "    print(\"‚úÖ Donn√©es charg√©es avec succ√®s !\")\n",
    "    print(f\"üìä Dataset original: {df_original.shape}\")\n",
    "    print(f\"üìä Dataset trait√©: {df_processed.shape}\")\n",
    "    \n",
    "    # Utiliser le dataset trait√© comme base\n",
    "    df = df_processed.copy()\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Fichiers de donn√©es non trouv√©s !\")\n",
    "    print(\"üí° Assurez-vous d'avoir ex√©cut√© le notebook 01_data_exploration.ipynb\")\n",
    "    \n",
    "    # Plan B : charger directement depuis le fichier source\n",
    "    print(\"üîÑ Chargement depuis le fichier source...\")\n",
    "    source_path = Path('../data/Housing Prices Dataset/Housing.csv')\n",
    "    \n",
    "    if source_path.exists():\n",
    "        df_original = pd.read_csv(source_path)\n",
    "        \n",
    "        # Appliquer les transformations de base\n",
    "        df = df_original.copy()\n",
    "        \n",
    "        # Variables binaires yes/no -> 1/0\n",
    "        binary_vars = ['mainroad', 'guestroom', 'basement', 'hotwaterheating', \n",
    "                       'airconditioning', 'prefarea']\n",
    "        \n",
    "        for var in binary_vars:\n",
    "            df[var] = df[var].map({'yes': 1, 'no': 0})\n",
    "        \n",
    "        # Variable furnishingstatus -> num√©rique\n",
    "        furnishing_map = {'furnished': 2, 'semi-furnished': 1, 'unfurnished': 0}\n",
    "        df['furnishingstatus'] = df['furnishingstatus'].map(furnishing_map)\n",
    "        \n",
    "        print(\"‚úÖ Donn√©es charg√©es et transform√©es !\")\n",
    "    else:\n",
    "        print(\"‚ùå Fichier source non trouv√© non plus !\")\n",
    "\n",
    "# 2. Aper√ßu des donn√©es charg√©es\n",
    "if 'df' in locals():\n",
    "    print(f\"\\nüîç APER√áU DES DONN√âES CHARG√âES:\")\n",
    "    print(f\"   Shape: {df.shape}\")\n",
    "    print(f\"   Variables num√©riques: {df.select_dtypes(include=[np.number]).shape[1]}\")\n",
    "    print(f\"   Variables cat√©gorielles: {df.select_dtypes(include=['object']).shape[1]}\")\n",
    "    print(f\"   Valeurs manquantes: {df.isnull().sum().sum()}\")\n",
    "    \n",
    "    print(f\"\\nüìã VARIABLES DISPONIBLES:\")\n",
    "    for i, col in enumerate(df.columns, 1):\n",
    "        col_type = \"Num√©rique\" if df[col].dtype in ['int64', 'float64'] else \"Cat√©gorielle\"\n",
    "        print(f\"   {i:2d}. {col:18s} ({col_type})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb020cba",
   "metadata": {},
   "source": [
    "## üö® Traitement Intelligent des Valeurs Aberrantes\n",
    "\n",
    "Nous allons traiter les outliers de mani√®re intelligente en analysant s'ils sont des erreurs ou des valeurs l√©gitimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59f5aca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fonctions de d√©tection d'outliers d√©finies !\n"
     ]
    }
   ],
   "source": [
    "# Fonctions utilitaires pour les outliers\n",
    "def detect_outliers_iqr(data, column):\n",
    "    \"\"\"D√©tecte les outliers avec la m√©thode IQR\"\"\"\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
    "    return outliers, lower_bound, upper_bound\n",
    "\n",
    "def detect_outliers_zscore(data, column, threshold=3):\n",
    "    \"\"\"D√©tecte les outliers avec la m√©thode Z-score\"\"\"\n",
    "    z_scores = np.abs(zscore(data[column]))\n",
    "    outliers = data[z_scores > threshold]\n",
    "    return outliers, z_scores\n",
    "\n",
    "def detect_outliers_isolation_forest(data, contamination=0.1):\n",
    "    \"\"\"D√©tecte les outliers avec Isolation Forest\"\"\"\n",
    "    # S√©lectionner seulement les variables num√©riques\n",
    "    numeric_cols = data.select_dtypes(include=[np.number]).columns\n",
    "    X = data[numeric_cols]\n",
    "    \n",
    "    iso_forest = IsolationForest(contamination=contamination, random_state=42)\n",
    "    outliers_pred = iso_forest.fit_predict(X)\n",
    "    \n",
    "    # -1 pour outliers, 1 pour normaux\n",
    "    outliers_mask = outliers_pred == -1\n",
    "    outliers = data[outliers_mask]\n",
    "    \n",
    "    return outliers, outliers_mask\n",
    "\n",
    "print(\"‚úÖ Fonctions de d√©tection d'outliers d√©finies !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "830cc02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ANALYSE D√âTAILL√âE DES VALEURS ABERRANTES\n",
      "==================================================\n",
      "\n",
      "üìä PRICE:\n",
      "   IQR Outliers: 15 (2.8%)\n",
      "   Z-score Outliers: 6 (1.1%)\n",
      "   IQR Seuils: [-35000.0, 9205000.0]\n",
      "   Valeurs extr√™mes: 9240000.0 - 13300000.0\n",
      "\n",
      "üìä AREA:\n",
      "   IQR Outliers: 12 (2.2%)\n",
      "   Z-score Outliers: 7 (1.3%)\n",
      "   IQR Seuils: [-540.0, 10500.0]\n",
      "   Valeurs extr√™mes: 10700.0 - 16200.0\n",
      "\n",
      "üìä BEDROOMS:\n",
      "   IQR Outliers: 12 (2.2%)\n",
      "   Z-score Outliers: 2 (0.4%)\n",
      "   IQR Seuils: [0.5, 4.5]\n",
      "   Valeurs extr√™mes: 5.0 - 6.0\n",
      "\n",
      "üìä BATHROOMS:\n",
      "   IQR Outliers: 1 (0.2%)\n",
      "   Z-score Outliers: 11 (2.0%)\n",
      "   IQR Seuils: [-0.5, 3.5]\n",
      "   Valeurs extr√™mes: 4.0 - 4.0\n",
      "\n",
      "üìä STORIES:\n",
      "   IQR Outliers: 41 (7.5%)\n",
      "   Z-score Outliers: 0 (0.0%)\n",
      "   IQR Seuils: [-0.5, 3.5]\n",
      "   Valeurs extr√™mes: 4.0 - 4.0\n",
      "\n",
      "üìä PARKING:\n",
      "   IQR Outliers: 12 (2.2%)\n",
      "   Z-score Outliers: 0 (0.0%)\n",
      "   IQR Seuils: [-1.5, 2.5]\n",
      "   Valeurs extr√™mes: 3.0 - 3.0\n",
      "\n",
      "ü§ñ D√âTECTION GLOBALE - ISOLATION FOREST:\n",
      "\n",
      "üìä PRICE:\n",
      "   IQR Outliers: 15 (2.8%)\n",
      "   Z-score Outliers: 6 (1.1%)\n",
      "   IQR Seuils: [-35000.0, 9205000.0]\n",
      "   Valeurs extr√™mes: 9240000.0 - 13300000.0\n",
      "\n",
      "üìä AREA:\n",
      "   IQR Outliers: 12 (2.2%)\n",
      "   Z-score Outliers: 7 (1.3%)\n",
      "   IQR Seuils: [-540.0, 10500.0]\n",
      "   Valeurs extr√™mes: 10700.0 - 16200.0\n",
      "\n",
      "üìä BEDROOMS:\n",
      "   IQR Outliers: 12 (2.2%)\n",
      "   Z-score Outliers: 2 (0.4%)\n",
      "   IQR Seuils: [0.5, 4.5]\n",
      "   Valeurs extr√™mes: 5.0 - 6.0\n",
      "\n",
      "üìä BATHROOMS:\n",
      "   IQR Outliers: 1 (0.2%)\n",
      "   Z-score Outliers: 11 (2.0%)\n",
      "   IQR Seuils: [-0.5, 3.5]\n",
      "   Valeurs extr√™mes: 4.0 - 4.0\n",
      "\n",
      "üìä STORIES:\n",
      "   IQR Outliers: 41 (7.5%)\n",
      "   Z-score Outliers: 0 (0.0%)\n",
      "   IQR Seuils: [-0.5, 3.5]\n",
      "   Valeurs extr√™mes: 4.0 - 4.0\n",
      "\n",
      "üìä PARKING:\n",
      "   IQR Outliers: 12 (2.2%)\n",
      "   Z-score Outliers: 0 (0.0%)\n",
      "   IQR Seuils: [-1.5, 2.5]\n",
      "   Valeurs extr√™mes: 3.0 - 3.0\n",
      "\n",
      "ü§ñ D√âTECTION GLOBALE - ISOLATION FOREST:\n",
      "   Outliers globaux d√©tect√©s: 28 (5.1%)\n",
      "\n",
      "üè† PROPRI√âT√âS AVEC OUTLIERS MULTIPLES:\n",
      "   Total propri√©t√©s avec outliers: 82\n",
      "\n",
      "   Exemples de propri√©t√©s extr√™mes:\n",
      "      price  area  bedrooms  bathrooms\n",
      "0  13300000  7420         4          2\n",
      "1  12250000  8960         4          4\n",
      "2  12250000  9960         3          2\n",
      "3  12215000  7500         4          2\n",
      "4  11410000  7420         4          1\n",
      "\n",
      "   Prix moyen avec outliers: 6,985,652\n",
      "   Prix moyen sans outliers: 4,373,745\n",
      "   Diff√©rence: 2,611,907\n",
      "   Outliers globaux d√©tect√©s: 28 (5.1%)\n",
      "\n",
      "üè† PROPRI√âT√âS AVEC OUTLIERS MULTIPLES:\n",
      "   Total propri√©t√©s avec outliers: 82\n",
      "\n",
      "   Exemples de propri√©t√©s extr√™mes:\n",
      "      price  area  bedrooms  bathrooms\n",
      "0  13300000  7420         4          2\n",
      "1  12250000  8960         4          4\n",
      "2  12250000  9960         3          2\n",
      "3  12215000  7500         4          2\n",
      "4  11410000  7420         4          1\n",
      "\n",
      "   Prix moyen avec outliers: 6,985,652\n",
      "   Prix moyen sans outliers: 4,373,745\n",
      "   Diff√©rence: 2,611,907\n"
     ]
    }
   ],
   "source": [
    "# 1. Analyse d√©taill√©e des outliers\n",
    "print(\"üîç ANALYSE D√âTAILL√âE DES VALEURS ABERRANTES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Variables √† analyser\n",
    "variables_to_analyze = ['price', 'area', 'bedrooms', 'bathrooms', 'stories', 'parking']\n",
    "outliers_summary = {}\n",
    "\n",
    "for var in variables_to_analyze:\n",
    "    if var in df.columns:\n",
    "        # M√©thode IQR\n",
    "        outliers_iqr, lower_iqr, upper_iqr = detect_outliers_iqr(df, var)\n",
    "        \n",
    "        # M√©thode Z-score\n",
    "        outliers_zscore, z_scores = detect_outliers_zscore(df, var)\n",
    "        \n",
    "        outliers_summary[var] = {\n",
    "            'iqr_count': len(outliers_iqr),\n",
    "            'zscore_count': len(outliers_zscore),\n",
    "            'iqr_bounds': (lower_iqr, upper_iqr),\n",
    "            'outliers_indices': set(outliers_iqr.index)\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nüìä {var.upper()}:\")\n",
    "        print(f\"   IQR Outliers: {len(outliers_iqr)} ({len(outliers_iqr)/len(df)*100:.1f}%)\")\n",
    "        print(f\"   Z-score Outliers: {len(outliers_zscore)} ({len(outliers_zscore)/len(df)*100:.1f}%)\")\n",
    "        print(f\"   IQR Seuils: [{lower_iqr:.1f}, {upper_iqr:.1f}]\")\n",
    "        \n",
    "        if len(outliers_iqr) > 0:\n",
    "            print(f\"   Valeurs extr√™mes: {outliers_iqr[var].min():.1f} - {outliers_iqr[var].max():.1f}\")\n",
    "\n",
    "# 2. Analyse globale avec Isolation Forest\n",
    "print(f\"\\nü§ñ D√âTECTION GLOBALE - ISOLATION FOREST:\")\n",
    "outliers_iso, outliers_mask = detect_outliers_isolation_forest(df, contamination=0.05)\n",
    "print(f\"   Outliers globaux d√©tect√©s: {len(outliers_iso)} ({len(outliers_iso)/len(df)*100:.1f}%)\")\n",
    "\n",
    "# 3. Analyse des propri√©t√©s avec outliers multiples\n",
    "print(f\"\\nüè† PROPRI√âT√âS AVEC OUTLIERS MULTIPLES:\")\n",
    "all_outlier_indices = set()\n",
    "for var, info in outliers_summary.items():\n",
    "    all_outlier_indices.update(info['outliers_indices'])\n",
    "\n",
    "if all_outlier_indices:\n",
    "    outlier_properties = df.loc[list(all_outlier_indices)]\n",
    "    print(f\"   Total propri√©t√©s avec outliers: {len(all_outlier_indices)}\")\n",
    "    print(f\"\\n   Exemples de propri√©t√©s extr√™mes:\")\n",
    "    display_cols = ['price', 'area', 'bedrooms', 'bathrooms']\n",
    "    print(outlier_properties[display_cols].head())\n",
    "    \n",
    "    # Prix moyens avec vs sans outliers\n",
    "    prix_avec_outliers = outlier_properties['price'].mean()\n",
    "    prix_sans_outliers = df.drop(all_outlier_indices)['price'].mean()\n",
    "    print(f\"\\n   Prix moyen avec outliers: {prix_avec_outliers:,.0f}\")\n",
    "    print(f\"   Prix moyen sans outliers: {prix_sans_outliers:,.0f}\")\n",
    "    print(f\"   Diff√©rence: {abs(prix_avec_outliers - prix_sans_outliers):,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb24238c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öñÔ∏è D√âCISION DE TRAITEMENT DES OUTLIERS\n",
      "=============================================\n",
      "üß¢ price: 12 valeurs limit√©es aux percentiles [1%, 99%] - Prix extr√™mes possibles dans l'immobilier\n",
      "üß¢ area: 12 valeurs limit√©es aux percentiles [1%, 99%] - Grandes propri√©t√©s possibles\n",
      "üóëÔ∏è bedrooms: 0 lignes supprim√©es (>10) - Plus de 10 chambres peu probable\n",
      "üóëÔ∏è bathrooms: 0 lignes supprim√©es (>8) - Plus de 8 SdB peu probable\n",
      "üóëÔ∏è stories: 0 lignes supprim√©es (>5) - Plus de 5 √©tages peu probable pour maison\n",
      "üóëÔ∏è parking: 0 lignes supprim√©es (>10) - Plus de 10 places peu probable\n",
      "\n",
      "üìä R√âSUM√â DU NETTOYAGE:\n",
      "   Lignes avant nettoyage: 545\n",
      "   Lignes apr√®s nettoyage: 545\n",
      "   Lignes supprim√©es: 0 (0.00%)\n",
      "\n",
      "üí∞ IMPACT SUR LES PRIX:\n",
      "   Prix moyen avant: 4,766,729\n",
      "   Prix moyen apr√®s: 4,751,146\n",
      "   √âcart-type avant: 1,870,440\n",
      "   √âcart-type apr√®s: 1,808,191\n",
      "\n",
      "‚úÖ Nettoyage des outliers termin√© ! Dataset final: (545, 13)\n"
     ]
    }
   ],
   "source": [
    "# 4. D√©cision de traitement des outliers\n",
    "print(\"‚öñÔ∏è D√âCISION DE TRAITEMENT DES OUTLIERS\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# Cr√©er une copie pour les tests\n",
    "df_clean = df.copy()\n",
    "outliers_removed = 0\n",
    "\n",
    "# R√®gles de traitement intelligentes\n",
    "treatment_rules = {\n",
    "    'price': {'action': 'cap', 'reason': 'Prix extr√™mes possibles dans l\\'immobilier'},\n",
    "    'area': {'action': 'cap', 'reason': 'Grandes propri√©t√©s possibles'},\n",
    "    'bedrooms': {'action': 'remove', 'max_reasonable': 10, 'reason': 'Plus de 10 chambres peu probable'},\n",
    "    'bathrooms': {'action': 'remove', 'max_reasonable': 8, 'reason': 'Plus de 8 SdB peu probable'},\n",
    "    'stories': {'action': 'remove', 'max_reasonable': 5, 'reason': 'Plus de 5 √©tages peu probable pour maison'},\n",
    "    'parking': {'action': 'remove', 'max_reasonable': 10, 'reason': 'Plus de 10 places peu probable'}\n",
    "}\n",
    "\n",
    "for var, rule in treatment_rules.items():\n",
    "    if var in df_clean.columns:\n",
    "        if rule['action'] == 'remove':\n",
    "            # Supprimer les valeurs d√©raisonnables\n",
    "            initial_count = len(df_clean)\n",
    "            df_clean = df_clean[df_clean[var] <= rule['max_reasonable']]\n",
    "            removed = initial_count - len(df_clean)\n",
    "            outliers_removed += removed\n",
    "            \n",
    "            print(f\"üóëÔ∏è {var}: {removed} lignes supprim√©es (>{rule['max_reasonable']}) - {rule['reason']}\")\n",
    "            \n",
    "        elif rule['action'] == 'cap':\n",
    "            # Limiter les valeurs extr√™mes aux percentiles\n",
    "            lower_bound = df_clean[var].quantile(0.01)  # 1er percentile\n",
    "            upper_bound = df_clean[var].quantile(0.99)  # 99e percentile\n",
    "            \n",
    "            initial_outliers = len(df_clean[(df_clean[var] < lower_bound) | (df_clean[var] > upper_bound)])\n",
    "            \n",
    "            # Appliquer le capping\n",
    "            df_clean[var] = df_clean[var].clip(lower=lower_bound, upper=upper_bound)\n",
    "            \n",
    "            print(f\"üß¢ {var}: {initial_outliers} valeurs limit√©es aux percentiles [1%, 99%] - {rule['reason']}\")\n",
    "\n",
    "print(f\"\\nüìä R√âSUM√â DU NETTOYAGE:\")\n",
    "print(f\"   Lignes avant nettoyage: {len(df):,}\")\n",
    "print(f\"   Lignes apr√®s nettoyage: {len(df_clean):,}\")\n",
    "print(f\"   Lignes supprim√©es: {len(df) - len(df_clean):,} ({(len(df) - len(df_clean))/len(df)*100:.2f}%)\")\n",
    "\n",
    "# V√©rifier l'impact sur les statistiques\n",
    "print(f\"\\nüí∞ IMPACT SUR LES PRIX:\")\n",
    "print(f\"   Prix moyen avant: {df['price'].mean():,.0f}\")\n",
    "print(f\"   Prix moyen apr√®s: {df_clean['price'].mean():,.0f}\")\n",
    "print(f\"   √âcart-type avant: {df['price'].std():,.0f}\")\n",
    "print(f\"   √âcart-type apr√®s: {df_clean['price'].std():,.0f}\")\n",
    "\n",
    "# Utiliser les donn√©es nettoy√©es\n",
    "df = df_clean.copy()\n",
    "print(f\"\\n‚úÖ Nettoyage des outliers termin√© ! Dataset final: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041db2ce",
   "metadata": {},
   "source": [
    "## üîß Ing√©nierie des Fonctionnalit√©s (Feature Engineering)\n",
    "\n",
    "Cr√©ons de nouvelles variables pertinentes pour am√©liorer les performances du mod√®le."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d525e2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß ING√âNIERIE DES FONCTIONNALIT√âS\n",
      "========================================\n",
      "‚úÖ Variables d√©riv√©es de base cr√©√©es:\n",
      "   ‚Ä¢ price_per_sqft: Prix par pied carr√©\n",
      "   ‚Ä¢ rooms_total: Nombre total de pi√®ces\n",
      "   ‚Ä¢ area_per_room: Surface par pi√®ce\n",
      "   ‚Ä¢ bathroom_bedroom_ratio: Ratio SdB/Chambres\n",
      "\n",
      "‚úÖ Variables d'√©quipements cr√©√©es:\n",
      "   ‚Ä¢ luxury_score: Score d'√©quipements de luxe (0-5)\n",
      "   ‚Ä¢ has_luxury: Pr√©sence d'au moins un √©quipement de luxe\n",
      "\n",
      "‚úÖ Cat√©gories cr√©√©es:\n",
      "   ‚Ä¢ size_category: Cat√©gorie de taille (small/medium/large/very_large)\n",
      "   ‚Ä¢ price_category: Gamme de prix (budget/mid_range/premium/luxury)\n",
      "\n",
      "‚úÖ Variables d'interaction cr√©√©es:\n",
      "   ‚Ä¢ area_bedrooms_interaction: Surface √ó Chambres\n",
      "   ‚Ä¢ luxury_area_interaction: Score luxe √ó Surface\n",
      "\n",
      "üìä APER√áU DES NOUVELLES VARIABLES:\n",
      "   price_per_sqft           :    991.0 (¬± 340.8)\n",
      "   rooms_total              :      4.3 (¬±   1.0)\n",
      "   area_per_room            :   1254.7 (¬± 556.3)\n",
      "   bathroom_bedroom_ratio   :      0.4 (¬±   0.2)\n",
      "   luxury_score             :      1.1 (¬±   1.1)\n",
      "   has_luxury               :      0.6 (¬±   0.5)\n",
      "\n",
      "üìä DISTRIBUTION DES CAT√âGORIES:\n",
      "   size_category:\n",
      "     small       : 309 (56.7%)\n",
      "     medium      : 183 (33.6%)\n",
      "     large       :  46 ( 8.4%)\n",
      "     very_large  :   7 ( 1.3%)\n",
      "   price_category:\n",
      "     budget      : 219 (40.2%)\n",
      "     mid_range   : 209 (38.3%)\n",
      "     premium     : 109 (20.0%)\n",
      "     luxury      :   8 ( 1.5%)\n",
      "\n",
      "‚úÖ Feature engineering termin√© ! Total variables: 23\n",
      "\n",
      "========================================\n",
      "‚úÖ Variables d√©riv√©es de base cr√©√©es:\n",
      "   ‚Ä¢ price_per_sqft: Prix par pied carr√©\n",
      "   ‚Ä¢ rooms_total: Nombre total de pi√®ces\n",
      "   ‚Ä¢ area_per_room: Surface par pi√®ce\n",
      "   ‚Ä¢ bathroom_bedroom_ratio: Ratio SdB/Chambres\n",
      "\n",
      "‚úÖ Variables d'√©quipements cr√©√©es:\n",
      "   ‚Ä¢ luxury_score: Score d'√©quipements de luxe (0-5)\n",
      "   ‚Ä¢ has_luxury: Pr√©sence d'au moins un √©quipement de luxe\n",
      "\n",
      "‚úÖ Cat√©gories cr√©√©es:\n",
      "   ‚Ä¢ size_category: Cat√©gorie de taille (small/medium/large/very_large)\n",
      "   ‚Ä¢ price_category: Gamme de prix (budget/mid_range/premium/luxury)\n",
      "\n",
      "‚úÖ Variables d'interaction cr√©√©es:\n",
      "   ‚Ä¢ area_bedrooms_interaction: Surface √ó Chambres\n",
      "   ‚Ä¢ luxury_area_interaction: Score luxe √ó Surface\n",
      "\n",
      "üìä APER√áU DES NOUVELLES VARIABLES:\n",
      "   price_per_sqft           :    991.0 (¬± 340.8)\n",
      "   rooms_total              :      4.3 (¬±   1.0)\n",
      "   area_per_room            :   1254.7 (¬± 556.3)\n",
      "   bathroom_bedroom_ratio   :      0.4 (¬±   0.2)\n",
      "   luxury_score             :      1.1 (¬±   1.1)\n",
      "   has_luxury               :      0.6 (¬±   0.5)\n",
      "\n",
      "üìä DISTRIBUTION DES CAT√âGORIES:\n",
      "   size_category:\n",
      "     small       : 309 (56.7%)\n",
      "     medium      : 183 (33.6%)\n",
      "     large       :  46 ( 8.4%)\n",
      "     very_large  :   7 ( 1.3%)\n",
      "   price_category:\n",
      "     budget      : 219 (40.2%)\n",
      "     mid_range   : 209 (38.3%)\n",
      "     premium     : 109 (20.0%)\n",
      "     luxury      :   8 ( 1.5%)\n",
      "\n",
      "‚úÖ Feature engineering termin√© ! Total variables: 23\n"
     ]
    }
   ],
   "source": [
    "# 1. Cr√©ation de nouvelles variables\n",
    "print(\"üîß ING√âNIERIE DES FONCTIONNALIT√âS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Variables d√©riv√©es de base\n",
    "df['price_per_sqft'] = df['price'] / df['area']\n",
    "df['rooms_total'] = df['bedrooms'] + df['bathrooms']\n",
    "df['area_per_room'] = df['area'] / df['rooms_total']\n",
    "df['bathroom_bedroom_ratio'] = df['bathrooms'] / df['bedrooms']\n",
    "\n",
    "print(\"‚úÖ Variables d√©riv√©es de base cr√©√©es:\")\n",
    "print(\"   ‚Ä¢ price_per_sqft: Prix par pied carr√©\")\n",
    "print(\"   ‚Ä¢ rooms_total: Nombre total de pi√®ces\")\n",
    "print(\"   ‚Ä¢ area_per_room: Surface par pi√®ce\")\n",
    "print(\"   ‚Ä¢ bathroom_bedroom_ratio: Ratio SdB/Chambres\")\n",
    "\n",
    "# 2. Variables d'√©quipements combin√©es\n",
    "luxury_features = ['guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea']\n",
    "df['luxury_score'] = df[luxury_features].sum(axis=1)\n",
    "df['has_luxury'] = (df['luxury_score'] > 0).astype(int)\n",
    "\n",
    "print(\"\\n‚úÖ Variables d'√©quipements cr√©√©es:\")\n",
    "print(\"   ‚Ä¢ luxury_score: Score d'√©quipements de luxe (0-5)\")\n",
    "print(\"   ‚Ä¢ has_luxury: Pr√©sence d'au moins un √©quipement de luxe\")\n",
    "\n",
    "# 3. Cat√©gorisation des tailles\n",
    "def categorize_size(area):\n",
    "    if area <= 5000:\n",
    "        return 'small'\n",
    "    elif area <= 8000:\n",
    "        return 'medium'\n",
    "    elif area <= 12000:\n",
    "        return 'large'\n",
    "    else:\n",
    "        return 'very_large'\n",
    "\n",
    "def categorize_price_range(price):\n",
    "    if price <= 4000000:\n",
    "        return 'budget'\n",
    "    elif price <= 6000000:\n",
    "        return 'mid_range'\n",
    "    elif price <= 10000000:\n",
    "        return 'premium'\n",
    "    else:\n",
    "        return 'luxury'\n",
    "\n",
    "df['size_category'] = df['area'].apply(categorize_size)\n",
    "df['price_category'] = df['price'].apply(categorize_price_range)\n",
    "\n",
    "print(\"\\n‚úÖ Cat√©gories cr√©√©es:\")\n",
    "print(\"   ‚Ä¢ size_category: Cat√©gorie de taille (small/medium/large/very_large)\")\n",
    "print(\"   ‚Ä¢ price_category: Gamme de prix (budget/mid_range/premium/luxury)\")\n",
    "\n",
    "# 4. Variables d'interaction importantes\n",
    "df['area_bedrooms_interaction'] = df['area'] * df['bedrooms']\n",
    "df['luxury_area_interaction'] = df['luxury_score'] * df['area']\n",
    "\n",
    "print(\"\\n‚úÖ Variables d'interaction cr√©√©es:\")\n",
    "print(\"   ‚Ä¢ area_bedrooms_interaction: Surface √ó Chambres\")\n",
    "print(\"   ‚Ä¢ luxury_area_interaction: Score luxe √ó Surface\")\n",
    "\n",
    "# 5. Aper√ßu des nouvelles variables\n",
    "new_features = ['price_per_sqft', 'rooms_total', 'area_per_room', 'bathroom_bedroom_ratio',\n",
    "                'luxury_score', 'has_luxury', 'size_category', 'price_category',\n",
    "                'area_bedrooms_interaction', 'luxury_area_interaction']\n",
    "\n",
    "print(f\"\\nüìä APER√áU DES NOUVELLES VARIABLES:\")\n",
    "for feature in new_features[:6]:  # Montrer les num√©riques d'abord\n",
    "    if df[feature].dtype in ['int64', 'float64']:\n",
    "        print(f\"   {feature:25s}: {df[feature].mean():8.1f} (¬±{df[feature].std():6.1f})\")\n",
    "\n",
    "print(f\"\\nüìä DISTRIBUTION DES CAT√âGORIES:\")\n",
    "for feature in ['size_category', 'price_category']:\n",
    "    print(f\"   {feature}:\")\n",
    "    counts = df[feature].value_counts()\n",
    "    for cat, count in counts.items():\n",
    "        pct = count/len(df)*100\n",
    "        print(f\"     {cat:12s}: {count:3d} ({pct:4.1f}%)\")\n",
    "\n",
    "print(f\"\\n‚úÖ Feature engineering termin√© ! Total variables: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c807b3e",
   "metadata": {},
   "source": [
    "## üìä Division des Donn√©es (Train/Validation/Test)\n",
    "\n",
    "Divisons nos donn√©es proprement pour l'entra√Ænement et l'√©valuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66d1c25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä PR√âPARATION POUR LA DIVISION DES DONN√âES\n",
      "==================================================\n",
      "üéØ Variable cible: price\n",
      "üìä Features num√©riques: 20\n",
      "üè∑Ô∏è Features cat√©gorielles: 1\n",
      "üìã Total features: 21\n",
      "\n",
      "üî¢ FEATURES NUM√âRIQUES:\n",
      "    1. area\n",
      "    2. bedrooms\n",
      "    3. bathrooms\n",
      "    4. stories\n",
      "    5. mainroad\n",
      "    6. guestroom\n",
      "    7. basement\n",
      "    8. hotwaterheating\n",
      "    9. airconditioning\n",
      "   10. parking\n",
      "   11. prefarea\n",
      "   12. furnishingstatus\n",
      "   13. price_per_sqft\n",
      "   14. rooms_total\n",
      "   15. area_per_room\n",
      "   16. bathroom_bedroom_ratio\n",
      "   17. luxury_score\n",
      "   18. has_luxury\n",
      "   19. area_bedrooms_interaction\n",
      "   20. luxury_area_interaction\n",
      "\n",
      "üè∑Ô∏è FEATURES CAT√âGORIELLES:\n",
      "    1. size_category\n",
      "       Valeurs: ['medium', 'large', 'very_large', 'small']\n",
      "\n",
      "üîÑ ENCODAGE ONE-HOT:\n",
      "   ‚úÖ size_category: 3 nouvelles variables\n",
      "\n",
      "üìä DATASET FINAL POUR LA MOD√âLISATION:\n",
      "   Shape X: (545, 23)\n",
      "   Shape y: (545,)\n",
      "   Total features apr√®s encodage: 23\n"
     ]
    }
   ],
   "source": [
    "# 1. Pr√©paration des variables pour la mod√©lisation\n",
    "print(\"üìä PR√âPARATION POUR LA DIVISION DES DONN√âES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Variables cibles\n",
    "target = 'price'\n",
    "y = df[target].copy()\n",
    "\n",
    "# S√©lection des variables pr√©dictives\n",
    "# Exclure la cible et les cat√©gories d√©riv√©es de la cible\n",
    "features_to_exclude = [target, 'price_category']\n",
    "feature_columns = [col for col in df.columns if col not in features_to_exclude]\n",
    "\n",
    "# S√©parer les variables num√©riques et cat√©gorielles\n",
    "numeric_features = df[feature_columns].select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_features = df[feature_columns].select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"üéØ Variable cible: {target}\")\n",
    "print(f\"üìä Features num√©riques: {len(numeric_features)}\")\n",
    "print(f\"üè∑Ô∏è Features cat√©gorielles: {len(categorical_features)}\")\n",
    "print(f\"üìã Total features: {len(numeric_features) + len(categorical_features)}\")\n",
    "\n",
    "print(f\"\\nüî¢ FEATURES NUM√âRIQUES:\")\n",
    "for i, feat in enumerate(numeric_features, 1):\n",
    "    print(f\"   {i:2d}. {feat}\")\n",
    "\n",
    "if categorical_features:\n",
    "    print(f\"\\nüè∑Ô∏è FEATURES CAT√âGORIELLES:\")\n",
    "    for i, feat in enumerate(categorical_features, 1):\n",
    "        print(f\"   {i:2d}. {feat}\")\n",
    "        unique_values = df[feat].unique()\n",
    "        print(f\"       Valeurs: {list(unique_values)}\")\n",
    "\n",
    "# Pr√©parer X (features) avec encodage des variables cat√©gorielles\n",
    "X = df[numeric_features].copy()\n",
    "\n",
    "# One-hot encoding pour les variables cat√©gorielles\n",
    "if categorical_features:\n",
    "    print(f\"\\nüîÑ ENCODAGE ONE-HOT:\")\n",
    "    for feat in categorical_features:\n",
    "        # One-hot encoding\n",
    "        dummies = pd.get_dummies(df[feat], prefix=feat, drop_first=True)\n",
    "        X = pd.concat([X, dummies], axis=1)\n",
    "        print(f\"   ‚úÖ {feat}: {len(dummies.columns)} nouvelles variables\")\n",
    "\n",
    "print(f\"\\nüìä DATASET FINAL POUR LA MOD√âLISATION:\")\n",
    "print(f\"   Shape X: {X.shape}\")\n",
    "print(f\"   Shape y: {y.shape}\")\n",
    "print(f\"   Total features apr√®s encodage: {X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd3c12fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÇÔ∏è DIVISION DES DONN√âES\n",
      "==============================\n",
      "üìä Stratification bas√©e sur les quartiles de prix:\n",
      "price\n",
      "Q1    137\n",
      "Q2    138\n",
      "Q3    134\n",
      "Q4    136\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üìä R√âPARTITION DES DONN√âES:\n",
      "   üèãÔ∏è Train: 327 √©chantillons (60.0%)\n",
      "   ‚úÖ Validation: 109 √©chantillons (20.0%)\n",
      "   üß™ Test: 109 √©chantillons (20.0%)\n",
      "   üìä Total: 545 √©chantillons\n",
      "\n",
      "üí∞ R√âPARTITION DES PRIX PAR ENSEMBLE:\n",
      "   Train     : 4,739,763 (¬±1,754,574) [1,870,400 - 10,542,000]\n",
      "   Validation: 4,815,660 (¬±1,973,180) [1,870,400 - 10,542,000]\n",
      "   Test      : 4,720,782 (¬±1,810,334) [1,870,400 - 10,150,000]\n",
      "\n",
      "‚úÖ Division des donn√©es termin√©e !\n",
      "üìä Features: 23\n",
      "üéØ Pr√™t pour la normalisation et la mod√©lisation\n"
     ]
    }
   ],
   "source": [
    "# 2. Division stratifi√©e des donn√©es\n",
    "print(\"‚úÇÔ∏è DIVISION DES DONN√âES\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Cr√©er des strates bas√©es sur les prix pour assurer une r√©partition √©quilibr√©e\n",
    "price_bins = pd.qcut(y, q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'])\n",
    "print(\"üìä Stratification bas√©e sur les quartiles de prix:\")\n",
    "print(price_bins.value_counts().sort_index())\n",
    "\n",
    "# Division principale: 80% train+val, 20% test\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=price_bins\n",
    ")\n",
    "\n",
    "# Recr√©er les strates pour les donn√©es temporaires\n",
    "price_bins_temp = pd.qcut(y_temp, q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'])\n",
    "\n",
    "# Division train/validation: 75% train, 25% validation du reste\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    test_size=0.25,  # 25% de 80% = 20% du total\n",
    "    random_state=42,\n",
    "    stratify=price_bins_temp\n",
    ")\n",
    "\n",
    "# R√©sum√© des divisions\n",
    "print(f\"\\nüìä R√âPARTITION DES DONN√âES:\")\n",
    "print(f\"   üèãÔ∏è Train: {X_train.shape[0]:3d} √©chantillons ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"   ‚úÖ Validation: {X_val.shape[0]:3d} √©chantillons ({X_val.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"   üß™ Test: {X_test.shape[0]:3d} √©chantillons ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"   üìä Total: {len(X):3d} √©chantillons\")\n",
    "\n",
    "# V√©rification de la r√©partition des prix dans chaque ensemble\n",
    "print(f\"\\nüí∞ R√âPARTITION DES PRIX PAR ENSEMBLE:\")\n",
    "sets_info = {\n",
    "    'Train': y_train,\n",
    "    'Validation': y_val,\n",
    "    'Test': y_test\n",
    "}\n",
    "\n",
    "for set_name, y_set in sets_info.items():\n",
    "    print(f\"   {set_name:10s}: {y_set.mean():8,.0f} (¬±{y_set.std():8,.0f}) [{y_set.min():7,.0f} - {y_set.max():8,.0f}]\")\n",
    "\n",
    "print(f\"\\n‚úÖ Division des donn√©es termin√©e !\")\n",
    "print(f\"üìä Features: {X_train.shape[1]}\")\n",
    "print(f\"üéØ Pr√™t pour la normalisation et la mod√©lisation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabacf77",
   "metadata": {},
   "source": [
    "## üîÑ Normalisation des Donn√©es\n",
    "\n",
    "Normalisons les donn√©es pour optimiser les performances des algorithmes de machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65305346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ NORMALISATION DES DONN√âES\n",
      "===================================\n",
      "üß™ COMPARAISON DES M√âTHODES DE NORMALISATION:\n",
      "\n",
      "üìä Variable exemple: price_per_sqft\n",
      "   Original: 1000.6 (¬±346.7)\n",
      "   StandardScaler: 0.000 (¬±1.000)\n",
      "   MinMaxScaler : 0.294 (¬±0.149)\n",
      "   RobustScaler : 0.112 (¬±0.822)\n",
      "\n",
      "‚öôÔ∏è APPLICATION DE LA NORMALISATION:\n",
      "‚úÖ RobustScaler appliqu√© √† tous les ensembles\n",
      "   Train normalis√©: (327, 23)\n",
      "   Validation normalis√©: (109, 23)\n",
      "   Test normalis√©: (109, 23)\n",
      "\n",
      "üìä V√âRIFICATION DE LA NORMALISATION:\n",
      "   Variables avec moyenne ~0 et std ~1: 5/23\n",
      "\n",
      "üìà STATISTIQUES APR√àS NORMALISATION (Train):\n",
      "   area                     :  0.215 (¬±0.751)\n",
      "   bedrooms                 : -0.046 (¬±0.735)\n",
      "   bathrooms                :  0.284 (¬±0.515)\n",
      "   stories                  : -0.220 (¬±0.847)\n",
      "   mainroad                 : -0.159 (¬±0.366)\n",
      "\n",
      "‚úÖ Normalisation termin√©e !\n",
      "üìä Donn√©es pr√™tes pour la mod√©lisation\n",
      "‚úÖ RobustScaler appliqu√© √† tous les ensembles\n",
      "   Train normalis√©: (327, 23)\n",
      "   Validation normalis√©: (109, 23)\n",
      "   Test normalis√©: (109, 23)\n",
      "\n",
      "üìä V√âRIFICATION DE LA NORMALISATION:\n",
      "   Variables avec moyenne ~0 et std ~1: 5/23\n",
      "\n",
      "üìà STATISTIQUES APR√àS NORMALISATION (Train):\n",
      "   area                     :  0.215 (¬±0.751)\n",
      "   bedrooms                 : -0.046 (¬±0.735)\n",
      "   bathrooms                :  0.284 (¬±0.515)\n",
      "   stories                  : -0.220 (¬±0.847)\n",
      "   mainroad                 : -0.159 (¬±0.366)\n",
      "\n",
      "‚úÖ Normalisation termin√©e !\n",
      "üìä Donn√©es pr√™tes pour la mod√©lisation\n"
     ]
    }
   ],
   "source": [
    "# 1. Comparaison des m√©thodes de normalisation\n",
    "print(\"üîÑ NORMALISATION DES DONN√âES\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Tester diff√©rentes m√©thodes de normalisation sur un √©chantillon\n",
    "scalers = {\n",
    "    'StandardScaler': StandardScaler(),\n",
    "    'MinMaxScaler': MinMaxScaler(),\n",
    "    'RobustScaler': RobustScaler()\n",
    "}\n",
    "\n",
    "print(\"üß™ COMPARAISON DES M√âTHODES DE NORMALISATION:\")\n",
    "sample_feature = 'price_per_sqft'\n",
    "\n",
    "if sample_feature in X_train.columns:\n",
    "    original_data = X_train[sample_feature]\n",
    "    print(f\"\\nüìä Variable exemple: {sample_feature}\")\n",
    "    print(f\"   Original: {original_data.mean():.1f} (¬±{original_data.std():.1f})\")\n",
    "    \n",
    "    for name, scaler in scalers.items():\n",
    "        # Normaliser la variable exemple\n",
    "        transformed = scaler.fit_transform(original_data.values.reshape(-1, 1)).flatten()\n",
    "        print(f\"   {name:13s}: {transformed.mean():.3f} (¬±{transformed.std():.3f})\")\n",
    "\n",
    "# 2. S√©lection et application de la m√©thode de normalisation\n",
    "print(f\"\\n‚öôÔ∏è APPLICATION DE LA NORMALISATION:\")\n",
    "\n",
    "# Utiliser RobustScaler car il est moins sensible aux outliers\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# Normaliser les donn√©es d'entra√Ænement\n",
    "X_train_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(X_train),\n",
    "    columns=X_train.columns,\n",
    "    index=X_train.index\n",
    ")\n",
    "\n",
    "# Normaliser les donn√©es de validation et test avec le m√™me scaler\n",
    "X_val_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_val),\n",
    "    columns=X_val.columns,\n",
    "    index=X_val.index\n",
    ")\n",
    "\n",
    "X_test_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_test),\n",
    "    columns=X_test.columns,\n",
    "    index=X_test.index\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ RobustScaler appliqu√© √† tous les ensembles\")\n",
    "print(f\"   Train normalis√©: {X_train_scaled.shape}\")\n",
    "print(f\"   Validation normalis√©: {X_val_scaled.shape}\")\n",
    "print(f\"   Test normalis√©: {X_test_scaled.shape}\")\n",
    "\n",
    "# 3. V√©rification de la normalisation\n",
    "print(f\"\\nüìä V√âRIFICATION DE LA NORMALISATION:\")\n",
    "print(f\"   Variables avec moyenne ~0 et std ~1: {(abs(X_train_scaled.mean()) < 0.1).sum()}/{X_train_scaled.shape[1]}\")\n",
    "\n",
    "# Montrer quelques statistiques\n",
    "print(f\"\\nüìà STATISTIQUES APR√àS NORMALISATION (Train):\")\n",
    "stats_sample = X_train_scaled.iloc[:, :5]  # Premi√®res 5 variables\n",
    "for col in stats_sample.columns:\n",
    "    mean_val = stats_sample[col].mean()\n",
    "    std_val = stats_sample[col].std()\n",
    "    print(f\"   {col:25s}: {mean_val:6.3f} (¬±{std_val:5.3f})\")\n",
    "\n",
    "print(f\"\\n‚úÖ Normalisation termin√©e !\")\n",
    "print(f\"üìä Donn√©es pr√™tes pour la mod√©lisation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0720f0",
   "metadata": {},
   "source": [
    "## üíæ Sauvegarde des Donn√©es Pr√©par√©es\n",
    "\n",
    "Sauvegardons toutes les donn√©es pr√©par√©es pour la mod√©lisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e8ff8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ SAUVEGARDE DES DONN√âES PR√âPAR√âES\n",
      "========================================\n",
      "‚úÖ Donn√©es brutes sauvegard√©es:\n",
      "   X_train_raw.csv: (327, 23)\n",
      "   X_val_raw.csv: (109, 23)\n",
      "   X_test_raw.csv: (109, 23)\n",
      "   y_train.csv, y_val.csv, y_test.csv\n",
      "\n",
      "‚úÖ Donn√©es normalis√©es sauvegard√©es:\n",
      "   X_train_scaled.csv: (327, 23)\n",
      "   X_val_scaled.csv: (109, 23)\n",
      "   X_test_scaled.csv: (109, 23)\n",
      "\n",
      "‚úÖ Dataset complet sauvegard√©:\n",
      "   housing_final_cleaned.csv: (545, 23)\n",
      "\n",
      "‚úÖ M√©tadonn√©es sauvegard√©es:\n",
      "   metadata.json\n",
      "\n",
      "üéØ R√âSUM√â FINAL - √âTAPE 2 TERMIN√âE\n",
      "=============================================\n",
      "‚úÖ Donn√©es nettoy√©es: 545 propri√©t√©s\n",
      "‚úÖ Features cr√©√©es: 23 variables\n",
      "‚úÖ Outliers trait√©s intelligemment\n",
      "‚úÖ Donn√©es divis√©es (train/val/test)\n",
      "‚úÖ Donn√©es normalis√©es avec RobustScaler\n",
      "‚úÖ Tout sauvegard√© dans ..\\data\\processed\n",
      "\n",
      "üöÄ PROCHAINE √âTAPE:\n",
      "   √âtape 3 - Mod√©lisation et √©valuation\n",
      "   üìä 327 √©chantillons d'entra√Ænement pr√™ts\n",
      "   üéØ 23 features pour pr√©dire les prix immobiliers\n"
     ]
    }
   ],
   "source": [
    "# 1. Sauvegarde des datasets\n",
    "print(\"üíæ SAUVEGARDE DES DONN√âES PR√âPAR√âES\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Cr√©er le dossier de sauvegarde\n",
    "save_path = Path('../data/processed')\n",
    "save_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Sauvegarder les donn√©es non normalis√©es\n",
    "X_train.to_csv(save_path / 'X_train_raw.csv', index=False)\n",
    "X_val.to_csv(save_path / 'X_val_raw.csv', index=False)\n",
    "X_test.to_csv(save_path / 'X_test_raw.csv', index=False)\n",
    "\n",
    "y_train.to_csv(save_path / 'y_train.csv', index=False)\n",
    "y_val.to_csv(save_path / 'y_val.csv', index=False)\n",
    "y_test.to_csv(save_path / 'y_test.csv', index=False)\n",
    "\n",
    "print(\"‚úÖ Donn√©es brutes sauvegard√©es:\")\n",
    "print(f\"   X_train_raw.csv: {X_train.shape}\")\n",
    "print(f\"   X_val_raw.csv: {X_val.shape}\")\n",
    "print(f\"   X_test_raw.csv: {X_test.shape}\")\n",
    "print(f\"   y_train.csv, y_val.csv, y_test.csv\")\n",
    "\n",
    "# Sauvegarder les donn√©es normalis√©es\n",
    "X_train_scaled.to_csv(save_path / 'X_train_scaled.csv', index=False)\n",
    "X_val_scaled.to_csv(save_path / 'X_val_scaled.csv', index=False)\n",
    "X_test_scaled.to_csv(save_path / 'X_test_scaled.csv', index=False)\n",
    "\n",
    "print(\"\\n‚úÖ Donn√©es normalis√©es sauvegard√©es:\")\n",
    "print(f\"   X_train_scaled.csv: {X_train_scaled.shape}\")\n",
    "print(f\"   X_val_scaled.csv: {X_val_scaled.shape}\")\n",
    "print(f\"   X_test_scaled.csv: {X_test_scaled.shape}\")\n",
    "\n",
    "# Sauvegarder le dataset complet avec les nouvelles features\n",
    "df.to_csv(save_path / 'housing_final_cleaned.csv', index=False)\n",
    "print(f\"\\n‚úÖ Dataset complet sauvegard√©:\")\n",
    "print(f\"   housing_final_cleaned.csv: {df.shape}\")\n",
    "\n",
    "# Sauvegarder les m√©tadonn√©es importantes\n",
    "metadata = {\n",
    "    'dataset_info': {\n",
    "        'total_samples': len(df),\n",
    "        'total_features': X_train.shape[1],\n",
    "        'train_samples': X_train.shape[0],\n",
    "        'val_samples': X_val.shape[0],\n",
    "        'test_samples': X_test.shape[0]\n",
    "    },\n",
    "    'features': {\n",
    "        'numeric_features': numeric_features,\n",
    "        'categorical_features': categorical_features,\n",
    "        'all_features': list(X_train.columns)\n",
    "    },\n",
    "    'target': target,\n",
    "    'scaler_used': 'RobustScaler'\n",
    "}\n",
    "\n",
    "import json\n",
    "with open(save_path / 'metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\n‚úÖ M√©tadonn√©es sauvegard√©es:\")\n",
    "print(f\"   metadata.json\")\n",
    "\n",
    "# 2. R√©sum√© final\n",
    "print(f\"\\nüéØ R√âSUM√â FINAL - √âTAPE 2 TERMIN√âE\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"‚úÖ Donn√©es nettoy√©es: {len(df)} propri√©t√©s\")\n",
    "print(f\"‚úÖ Features cr√©√©es: {X_train.shape[1]} variables\")\n",
    "print(f\"‚úÖ Outliers trait√©s intelligemment\")\n",
    "print(f\"‚úÖ Donn√©es divis√©es (train/val/test)\")\n",
    "print(f\"‚úÖ Donn√©es normalis√©es avec RobustScaler\")\n",
    "print(f\"‚úÖ Tout sauvegard√© dans {save_path}\")\n",
    "\n",
    "print(f\"\\nüöÄ PROCHAINE √âTAPE:\")\n",
    "print(f\"   √âtape 3 - Mod√©lisation et √©valuation\")\n",
    "print(f\"   üìä {X_train.shape[0]} √©chantillons d'entra√Ænement pr√™ts\")\n",
    "print(f\"   üéØ {X_train.shape[1]} features pour pr√©dire les prix immobiliers\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
