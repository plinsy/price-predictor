{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6216ce74",
   "metadata": {},
   "source": [
    "# 🧹 Étape 2 : Nettoyage et Préparation des Données\n",
    "\n",
    "## 📋 Objectifs de cette étape\n",
    "1. **Charger** les données explorées de l'étape 1\n",
    "2. **Traiter** les valeurs aberrantes intelligemment\n",
    "3. **Encoder** les variables catégorielles\n",
    "4. **Ingénierie** des fonctionnalités (feature engineering)\n",
    "5. **Diviser** les données (train/validation/test)\n",
    "6. **Normaliser** les données pour la modélisation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c39fab2",
   "metadata": {},
   "source": [
    "## 🛠️ Configuration et Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c35a18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Configuration terminée !\n",
      "📦 Pandas version: 2.3.2\n",
      "📊 NumPy version: 2.3.3\n",
      "🤖 Scikit-learn importé avec succès\n"
     ]
    }
   ],
   "source": [
    "# Configuration générale\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Manipulation des données\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Statistiques\n",
    "from scipy import stats\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Configuration des graphiques\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Paramètres d'affichage\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "print(\"✅ Configuration terminée !\")\n",
    "print(f\"📦 Pandas version: {pd.__version__}\")\n",
    "print(f\"📊 NumPy version: {np.__version__}\")\n",
    "print(f\"🤖 Scikit-learn importé avec succès\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d381923",
   "metadata": {},
   "source": [
    "## 📊 Chargement des Données Explorées\n",
    "\n",
    "Nous allons charger les données nettoyées de l'étape 1 d'exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4205ed29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Données chargées avec succès !\n",
      "📊 Dataset original: (545, 14)\n",
      "📊 Dataset traité: (545, 13)\n",
      "\n",
      "🔍 APERÇU DES DONNÉES CHARGÉES:\n",
      "   Shape: (545, 13)\n",
      "   Variables numériques: 13\n",
      "   Variables catégorielles: 0\n",
      "   Valeurs manquantes: 0\n",
      "\n",
      "📋 VARIABLES DISPONIBLES:\n",
      "    1. price              (Numérique)\n",
      "    2. area               (Numérique)\n",
      "    3. bedrooms           (Numérique)\n",
      "    4. bathrooms          (Numérique)\n",
      "    5. stories            (Numérique)\n",
      "    6. mainroad           (Numérique)\n",
      "    7. guestroom          (Numérique)\n",
      "    8. basement           (Numérique)\n",
      "    9. hotwaterheating    (Numérique)\n",
      "   10. airconditioning    (Numérique)\n",
      "   11. parking            (Numérique)\n",
      "   12. prefarea           (Numérique)\n",
      "   13. furnishingstatus   (Numérique)\n"
     ]
    }
   ],
   "source": [
    "# 1. Chargement des données depuis l'étape 1\n",
    "processed_data_path = Path('../data/processed')\n",
    "\n",
    "# Vérifier que les fichiers existent\n",
    "original_file = processed_data_path / 'housing_original.csv'\n",
    "processed_file = processed_data_path / 'housing_processed.csv'\n",
    "\n",
    "if original_file.exists() and processed_file.exists():\n",
    "    # Charger les deux versions\n",
    "    df_original = pd.read_csv(original_file)\n",
    "    df_processed = pd.read_csv(processed_file)\n",
    "    \n",
    "    print(\"✅ Données chargées avec succès !\")\n",
    "    print(f\"📊 Dataset original: {df_original.shape}\")\n",
    "    print(f\"📊 Dataset traité: {df_processed.shape}\")\n",
    "    \n",
    "    # Utiliser le dataset traité comme base\n",
    "    df = df_processed.copy()\n",
    "    \n",
    "else:\n",
    "    print(\"❌ Fichiers de données non trouvés !\")\n",
    "    print(\"💡 Assurez-vous d'avoir exécuté le notebook 01_data_exploration.ipynb\")\n",
    "    \n",
    "    # Plan B : charger directement depuis le fichier source\n",
    "    print(\"🔄 Chargement depuis le fichier source...\")\n",
    "    source_path = Path('../data/Housing Prices Dataset/Housing.csv')\n",
    "    \n",
    "    if source_path.exists():\n",
    "        df_original = pd.read_csv(source_path)\n",
    "        \n",
    "        # Appliquer les transformations de base\n",
    "        df = df_original.copy()\n",
    "        \n",
    "        # Variables binaires yes/no -> 1/0\n",
    "        binary_vars = ['mainroad', 'guestroom', 'basement', 'hotwaterheating', \n",
    "                       'airconditioning', 'prefarea']\n",
    "        \n",
    "        for var in binary_vars:\n",
    "            df[var] = df[var].map({'yes': 1, 'no': 0})\n",
    "        \n",
    "        # Variable furnishingstatus -> numérique\n",
    "        furnishing_map = {'furnished': 2, 'semi-furnished': 1, 'unfurnished': 0}\n",
    "        df['furnishingstatus'] = df['furnishingstatus'].map(furnishing_map)\n",
    "        \n",
    "        print(\"✅ Données chargées et transformées !\")\n",
    "    else:\n",
    "        print(\"❌ Fichier source non trouvé non plus !\")\n",
    "\n",
    "# 2. Aperçu des données chargées\n",
    "if 'df' in locals():\n",
    "    print(f\"\\n🔍 APERÇU DES DONNÉES CHARGÉES:\")\n",
    "    print(f\"   Shape: {df.shape}\")\n",
    "    print(f\"   Variables numériques: {df.select_dtypes(include=[np.number]).shape[1]}\")\n",
    "    print(f\"   Variables catégorielles: {df.select_dtypes(include=['object']).shape[1]}\")\n",
    "    print(f\"   Valeurs manquantes: {df.isnull().sum().sum()}\")\n",
    "    \n",
    "    print(f\"\\n📋 VARIABLES DISPONIBLES:\")\n",
    "    for i, col in enumerate(df.columns, 1):\n",
    "        col_type = \"Numérique\" if df[col].dtype in ['int64', 'float64'] else \"Catégorielle\"\n",
    "        print(f\"   {i:2d}. {col:18s} ({col_type})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb020cba",
   "metadata": {},
   "source": [
    "## 🚨 Traitement Intelligent des Valeurs Aberrantes\n",
    "\n",
    "Nous allons traiter les outliers de manière intelligente en analysant s'ils sont des erreurs ou des valeurs légitimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59f5aca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fonctions de détection d'outliers définies !\n"
     ]
    }
   ],
   "source": [
    "# Fonctions utilitaires pour les outliers\n",
    "def detect_outliers_iqr(data, column):\n",
    "    \"\"\"Détecte les outliers avec la méthode IQR\"\"\"\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
    "    return outliers, lower_bound, upper_bound\n",
    "\n",
    "def detect_outliers_zscore(data, column, threshold=3):\n",
    "    \"\"\"Détecte les outliers avec la méthode Z-score\"\"\"\n",
    "    z_scores = np.abs(zscore(data[column]))\n",
    "    outliers = data[z_scores > threshold]\n",
    "    return outliers, z_scores\n",
    "\n",
    "def detect_outliers_isolation_forest(data, contamination=0.1):\n",
    "    \"\"\"Détecte les outliers avec Isolation Forest\"\"\"\n",
    "    # Sélectionner seulement les variables numériques\n",
    "    numeric_cols = data.select_dtypes(include=[np.number]).columns\n",
    "    X = data[numeric_cols]\n",
    "    \n",
    "    iso_forest = IsolationForest(contamination=contamination, random_state=42)\n",
    "    outliers_pred = iso_forest.fit_predict(X)\n",
    "    \n",
    "    # -1 pour outliers, 1 pour normaux\n",
    "    outliers_mask = outliers_pred == -1\n",
    "    outliers = data[outliers_mask]\n",
    "    \n",
    "    return outliers, outliers_mask\n",
    "\n",
    "print(\"✅ Fonctions de détection d'outliers définies !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "830cc02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 ANALYSE DÉTAILLÉE DES VALEURS ABERRANTES\n",
      "==================================================\n",
      "\n",
      "📊 PRICE:\n",
      "   IQR Outliers: 15 (2.8%)\n",
      "   Z-score Outliers: 6 (1.1%)\n",
      "   IQR Seuils: [-35000.0, 9205000.0]\n",
      "   Valeurs extrêmes: 9240000.0 - 13300000.0\n",
      "\n",
      "📊 AREA:\n",
      "   IQR Outliers: 12 (2.2%)\n",
      "   Z-score Outliers: 7 (1.3%)\n",
      "   IQR Seuils: [-540.0, 10500.0]\n",
      "   Valeurs extrêmes: 10700.0 - 16200.0\n",
      "\n",
      "📊 BEDROOMS:\n",
      "   IQR Outliers: 12 (2.2%)\n",
      "   Z-score Outliers: 2 (0.4%)\n",
      "   IQR Seuils: [0.5, 4.5]\n",
      "   Valeurs extrêmes: 5.0 - 6.0\n",
      "\n",
      "📊 BATHROOMS:\n",
      "   IQR Outliers: 1 (0.2%)\n",
      "   Z-score Outliers: 11 (2.0%)\n",
      "   IQR Seuils: [-0.5, 3.5]\n",
      "   Valeurs extrêmes: 4.0 - 4.0\n",
      "\n",
      "📊 STORIES:\n",
      "   IQR Outliers: 41 (7.5%)\n",
      "   Z-score Outliers: 0 (0.0%)\n",
      "   IQR Seuils: [-0.5, 3.5]\n",
      "   Valeurs extrêmes: 4.0 - 4.0\n",
      "\n",
      "📊 PARKING:\n",
      "   IQR Outliers: 12 (2.2%)\n",
      "   Z-score Outliers: 0 (0.0%)\n",
      "   IQR Seuils: [-1.5, 2.5]\n",
      "   Valeurs extrêmes: 3.0 - 3.0\n",
      "\n",
      "🤖 DÉTECTION GLOBALE - ISOLATION FOREST:\n",
      "\n",
      "📊 PRICE:\n",
      "   IQR Outliers: 15 (2.8%)\n",
      "   Z-score Outliers: 6 (1.1%)\n",
      "   IQR Seuils: [-35000.0, 9205000.0]\n",
      "   Valeurs extrêmes: 9240000.0 - 13300000.0\n",
      "\n",
      "📊 AREA:\n",
      "   IQR Outliers: 12 (2.2%)\n",
      "   Z-score Outliers: 7 (1.3%)\n",
      "   IQR Seuils: [-540.0, 10500.0]\n",
      "   Valeurs extrêmes: 10700.0 - 16200.0\n",
      "\n",
      "📊 BEDROOMS:\n",
      "   IQR Outliers: 12 (2.2%)\n",
      "   Z-score Outliers: 2 (0.4%)\n",
      "   IQR Seuils: [0.5, 4.5]\n",
      "   Valeurs extrêmes: 5.0 - 6.0\n",
      "\n",
      "📊 BATHROOMS:\n",
      "   IQR Outliers: 1 (0.2%)\n",
      "   Z-score Outliers: 11 (2.0%)\n",
      "   IQR Seuils: [-0.5, 3.5]\n",
      "   Valeurs extrêmes: 4.0 - 4.0\n",
      "\n",
      "📊 STORIES:\n",
      "   IQR Outliers: 41 (7.5%)\n",
      "   Z-score Outliers: 0 (0.0%)\n",
      "   IQR Seuils: [-0.5, 3.5]\n",
      "   Valeurs extrêmes: 4.0 - 4.0\n",
      "\n",
      "📊 PARKING:\n",
      "   IQR Outliers: 12 (2.2%)\n",
      "   Z-score Outliers: 0 (0.0%)\n",
      "   IQR Seuils: [-1.5, 2.5]\n",
      "   Valeurs extrêmes: 3.0 - 3.0\n",
      "\n",
      "🤖 DÉTECTION GLOBALE - ISOLATION FOREST:\n",
      "   Outliers globaux détectés: 28 (5.1%)\n",
      "\n",
      "🏠 PROPRIÉTÉS AVEC OUTLIERS MULTIPLES:\n",
      "   Total propriétés avec outliers: 82\n",
      "\n",
      "   Exemples de propriétés extrêmes:\n",
      "      price  area  bedrooms  bathrooms\n",
      "0  13300000  7420         4          2\n",
      "1  12250000  8960         4          4\n",
      "2  12250000  9960         3          2\n",
      "3  12215000  7500         4          2\n",
      "4  11410000  7420         4          1\n",
      "\n",
      "   Prix moyen avec outliers: 6,985,652\n",
      "   Prix moyen sans outliers: 4,373,745\n",
      "   Différence: 2,611,907\n",
      "   Outliers globaux détectés: 28 (5.1%)\n",
      "\n",
      "🏠 PROPRIÉTÉS AVEC OUTLIERS MULTIPLES:\n",
      "   Total propriétés avec outliers: 82\n",
      "\n",
      "   Exemples de propriétés extrêmes:\n",
      "      price  area  bedrooms  bathrooms\n",
      "0  13300000  7420         4          2\n",
      "1  12250000  8960         4          4\n",
      "2  12250000  9960         3          2\n",
      "3  12215000  7500         4          2\n",
      "4  11410000  7420         4          1\n",
      "\n",
      "   Prix moyen avec outliers: 6,985,652\n",
      "   Prix moyen sans outliers: 4,373,745\n",
      "   Différence: 2,611,907\n"
     ]
    }
   ],
   "source": [
    "# 1. Analyse détaillée des outliers\n",
    "print(\"🔍 ANALYSE DÉTAILLÉE DES VALEURS ABERRANTES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Variables à analyser\n",
    "variables_to_analyze = ['price', 'area', 'bedrooms', 'bathrooms', 'stories', 'parking']\n",
    "outliers_summary = {}\n",
    "\n",
    "for var in variables_to_analyze:\n",
    "    if var in df.columns:\n",
    "        # Méthode IQR\n",
    "        outliers_iqr, lower_iqr, upper_iqr = detect_outliers_iqr(df, var)\n",
    "        \n",
    "        # Méthode Z-score\n",
    "        outliers_zscore, z_scores = detect_outliers_zscore(df, var)\n",
    "        \n",
    "        outliers_summary[var] = {\n",
    "            'iqr_count': len(outliers_iqr),\n",
    "            'zscore_count': len(outliers_zscore),\n",
    "            'iqr_bounds': (lower_iqr, upper_iqr),\n",
    "            'outliers_indices': set(outliers_iqr.index)\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n📊 {var.upper()}:\")\n",
    "        print(f\"   IQR Outliers: {len(outliers_iqr)} ({len(outliers_iqr)/len(df)*100:.1f}%)\")\n",
    "        print(f\"   Z-score Outliers: {len(outliers_zscore)} ({len(outliers_zscore)/len(df)*100:.1f}%)\")\n",
    "        print(f\"   IQR Seuils: [{lower_iqr:.1f}, {upper_iqr:.1f}]\")\n",
    "        \n",
    "        if len(outliers_iqr) > 0:\n",
    "            print(f\"   Valeurs extrêmes: {outliers_iqr[var].min():.1f} - {outliers_iqr[var].max():.1f}\")\n",
    "\n",
    "# 2. Analyse globale avec Isolation Forest\n",
    "print(f\"\\n🤖 DÉTECTION GLOBALE - ISOLATION FOREST:\")\n",
    "outliers_iso, outliers_mask = detect_outliers_isolation_forest(df, contamination=0.05)\n",
    "print(f\"   Outliers globaux détectés: {len(outliers_iso)} ({len(outliers_iso)/len(df)*100:.1f}%)\")\n",
    "\n",
    "# 3. Analyse des propriétés avec outliers multiples\n",
    "print(f\"\\n🏠 PROPRIÉTÉS AVEC OUTLIERS MULTIPLES:\")\n",
    "all_outlier_indices = set()\n",
    "for var, info in outliers_summary.items():\n",
    "    all_outlier_indices.update(info['outliers_indices'])\n",
    "\n",
    "if all_outlier_indices:\n",
    "    outlier_properties = df.loc[list(all_outlier_indices)]\n",
    "    print(f\"   Total propriétés avec outliers: {len(all_outlier_indices)}\")\n",
    "    print(f\"\\n   Exemples de propriétés extrêmes:\")\n",
    "    display_cols = ['price', 'area', 'bedrooms', 'bathrooms']\n",
    "    print(outlier_properties[display_cols].head())\n",
    "    \n",
    "    # Prix moyens avec vs sans outliers\n",
    "    prix_avec_outliers = outlier_properties['price'].mean()\n",
    "    prix_sans_outliers = df.drop(all_outlier_indices)['price'].mean()\n",
    "    print(f\"\\n   Prix moyen avec outliers: {prix_avec_outliers:,.0f}\")\n",
    "    print(f\"   Prix moyen sans outliers: {prix_sans_outliers:,.0f}\")\n",
    "    print(f\"   Différence: {abs(prix_avec_outliers - prix_sans_outliers):,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb24238c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚖️ DÉCISION DE TRAITEMENT DES OUTLIERS\n",
      "=============================================\n",
      "🧢 price: 12 valeurs limitées aux percentiles [1%, 99%] - Prix extrêmes possibles dans l'immobilier\n",
      "🧢 area: 12 valeurs limitées aux percentiles [1%, 99%] - Grandes propriétés possibles\n",
      "🗑️ bedrooms: 0 lignes supprimées (>10) - Plus de 10 chambres peu probable\n",
      "🗑️ bathrooms: 0 lignes supprimées (>8) - Plus de 8 SdB peu probable\n",
      "🗑️ stories: 0 lignes supprimées (>5) - Plus de 5 étages peu probable pour maison\n",
      "🗑️ parking: 0 lignes supprimées (>10) - Plus de 10 places peu probable\n",
      "\n",
      "📊 RÉSUMÉ DU NETTOYAGE:\n",
      "   Lignes avant nettoyage: 545\n",
      "   Lignes après nettoyage: 545\n",
      "   Lignes supprimées: 0 (0.00%)\n",
      "\n",
      "💰 IMPACT SUR LES PRIX:\n",
      "   Prix moyen avant: 4,766,729\n",
      "   Prix moyen après: 4,751,146\n",
      "   Écart-type avant: 1,870,440\n",
      "   Écart-type après: 1,808,191\n",
      "\n",
      "✅ Nettoyage des outliers terminé ! Dataset final: (545, 13)\n"
     ]
    }
   ],
   "source": [
    "# 4. Décision de traitement des outliers\n",
    "print(\"⚖️ DÉCISION DE TRAITEMENT DES OUTLIERS\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# Créer une copie pour les tests\n",
    "df_clean = df.copy()\n",
    "outliers_removed = 0\n",
    "\n",
    "# Règles de traitement intelligentes\n",
    "treatment_rules = {\n",
    "    'price': {'action': 'cap', 'reason': 'Prix extrêmes possibles dans l\\'immobilier'},\n",
    "    'area': {'action': 'cap', 'reason': 'Grandes propriétés possibles'},\n",
    "    'bedrooms': {'action': 'remove', 'max_reasonable': 10, 'reason': 'Plus de 10 chambres peu probable'},\n",
    "    'bathrooms': {'action': 'remove', 'max_reasonable': 8, 'reason': 'Plus de 8 SdB peu probable'},\n",
    "    'stories': {'action': 'remove', 'max_reasonable': 5, 'reason': 'Plus de 5 étages peu probable pour maison'},\n",
    "    'parking': {'action': 'remove', 'max_reasonable': 10, 'reason': 'Plus de 10 places peu probable'}\n",
    "}\n",
    "\n",
    "for var, rule in treatment_rules.items():\n",
    "    if var in df_clean.columns:\n",
    "        if rule['action'] == 'remove':\n",
    "            # Supprimer les valeurs déraisonnables\n",
    "            initial_count = len(df_clean)\n",
    "            df_clean = df_clean[df_clean[var] <= rule['max_reasonable']]\n",
    "            removed = initial_count - len(df_clean)\n",
    "            outliers_removed += removed\n",
    "            \n",
    "            print(f\"🗑️ {var}: {removed} lignes supprimées (>{rule['max_reasonable']}) - {rule['reason']}\")\n",
    "            \n",
    "        elif rule['action'] == 'cap':\n",
    "            # Limiter les valeurs extrêmes aux percentiles\n",
    "            lower_bound = df_clean[var].quantile(0.01)  # 1er percentile\n",
    "            upper_bound = df_clean[var].quantile(0.99)  # 99e percentile\n",
    "            \n",
    "            initial_outliers = len(df_clean[(df_clean[var] < lower_bound) | (df_clean[var] > upper_bound)])\n",
    "            \n",
    "            # Appliquer le capping\n",
    "            df_clean[var] = df_clean[var].clip(lower=lower_bound, upper=upper_bound)\n",
    "            \n",
    "            print(f\"🧢 {var}: {initial_outliers} valeurs limitées aux percentiles [1%, 99%] - {rule['reason']}\")\n",
    "\n",
    "print(f\"\\n📊 RÉSUMÉ DU NETTOYAGE:\")\n",
    "print(f\"   Lignes avant nettoyage: {len(df):,}\")\n",
    "print(f\"   Lignes après nettoyage: {len(df_clean):,}\")\n",
    "print(f\"   Lignes supprimées: {len(df) - len(df_clean):,} ({(len(df) - len(df_clean))/len(df)*100:.2f}%)\")\n",
    "\n",
    "# Vérifier l'impact sur les statistiques\n",
    "print(f\"\\n💰 IMPACT SUR LES PRIX:\")\n",
    "print(f\"   Prix moyen avant: {df['price'].mean():,.0f}\")\n",
    "print(f\"   Prix moyen après: {df_clean['price'].mean():,.0f}\")\n",
    "print(f\"   Écart-type avant: {df['price'].std():,.0f}\")\n",
    "print(f\"   Écart-type après: {df_clean['price'].std():,.0f}\")\n",
    "\n",
    "# Utiliser les données nettoyées\n",
    "df = df_clean.copy()\n",
    "print(f\"\\n✅ Nettoyage des outliers terminé ! Dataset final: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041db2ce",
   "metadata": {},
   "source": [
    "## 🔧 Ingénierie des Fonctionnalités (Feature Engineering)\n",
    "\n",
    "Créons de nouvelles variables pertinentes pour améliorer les performances du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d525e2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 INGÉNIERIE DES FONCTIONNALITÉS\n",
      "========================================\n",
      "✅ Variables dérivées de base créées:\n",
      "   • price_per_sqft: Prix par pied carré\n",
      "   • rooms_total: Nombre total de pièces\n",
      "   • area_per_room: Surface par pièce\n",
      "   • bathroom_bedroom_ratio: Ratio SdB/Chambres\n",
      "\n",
      "✅ Variables d'équipements créées:\n",
      "   • luxury_score: Score d'équipements de luxe (0-5)\n",
      "   • has_luxury: Présence d'au moins un équipement de luxe\n",
      "\n",
      "✅ Catégories créées:\n",
      "   • size_category: Catégorie de taille (small/medium/large/very_large)\n",
      "   • price_category: Gamme de prix (budget/mid_range/premium/luxury)\n",
      "\n",
      "✅ Variables d'interaction créées:\n",
      "   • area_bedrooms_interaction: Surface × Chambres\n",
      "   • luxury_area_interaction: Score luxe × Surface\n",
      "\n",
      "📊 APERÇU DES NOUVELLES VARIABLES:\n",
      "   price_per_sqft           :    991.0 (± 340.8)\n",
      "   rooms_total              :      4.3 (±   1.0)\n",
      "   area_per_room            :   1254.7 (± 556.3)\n",
      "   bathroom_bedroom_ratio   :      0.4 (±   0.2)\n",
      "   luxury_score             :      1.1 (±   1.1)\n",
      "   has_luxury               :      0.6 (±   0.5)\n",
      "\n",
      "📊 DISTRIBUTION DES CATÉGORIES:\n",
      "   size_category:\n",
      "     small       : 309 (56.7%)\n",
      "     medium      : 183 (33.6%)\n",
      "     large       :  46 ( 8.4%)\n",
      "     very_large  :   7 ( 1.3%)\n",
      "   price_category:\n",
      "     budget      : 219 (40.2%)\n",
      "     mid_range   : 209 (38.3%)\n",
      "     premium     : 109 (20.0%)\n",
      "     luxury      :   8 ( 1.5%)\n",
      "\n",
      "✅ Feature engineering terminé ! Total variables: 23\n",
      "\n",
      "========================================\n",
      "✅ Variables dérivées de base créées:\n",
      "   • price_per_sqft: Prix par pied carré\n",
      "   • rooms_total: Nombre total de pièces\n",
      "   • area_per_room: Surface par pièce\n",
      "   • bathroom_bedroom_ratio: Ratio SdB/Chambres\n",
      "\n",
      "✅ Variables d'équipements créées:\n",
      "   • luxury_score: Score d'équipements de luxe (0-5)\n",
      "   • has_luxury: Présence d'au moins un équipement de luxe\n",
      "\n",
      "✅ Catégories créées:\n",
      "   • size_category: Catégorie de taille (small/medium/large/very_large)\n",
      "   • price_category: Gamme de prix (budget/mid_range/premium/luxury)\n",
      "\n",
      "✅ Variables d'interaction créées:\n",
      "   • area_bedrooms_interaction: Surface × Chambres\n",
      "   • luxury_area_interaction: Score luxe × Surface\n",
      "\n",
      "📊 APERÇU DES NOUVELLES VARIABLES:\n",
      "   price_per_sqft           :    991.0 (± 340.8)\n",
      "   rooms_total              :      4.3 (±   1.0)\n",
      "   area_per_room            :   1254.7 (± 556.3)\n",
      "   bathroom_bedroom_ratio   :      0.4 (±   0.2)\n",
      "   luxury_score             :      1.1 (±   1.1)\n",
      "   has_luxury               :      0.6 (±   0.5)\n",
      "\n",
      "📊 DISTRIBUTION DES CATÉGORIES:\n",
      "   size_category:\n",
      "     small       : 309 (56.7%)\n",
      "     medium      : 183 (33.6%)\n",
      "     large       :  46 ( 8.4%)\n",
      "     very_large  :   7 ( 1.3%)\n",
      "   price_category:\n",
      "     budget      : 219 (40.2%)\n",
      "     mid_range   : 209 (38.3%)\n",
      "     premium     : 109 (20.0%)\n",
      "     luxury      :   8 ( 1.5%)\n",
      "\n",
      "✅ Feature engineering terminé ! Total variables: 23\n"
     ]
    }
   ],
   "source": [
    "# 1. Création de nouvelles variables\n",
    "print(\"🔧 INGÉNIERIE DES FONCTIONNALITÉS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Variables dérivées de base\n",
    "df['price_per_sqft'] = df['price'] / df['area']\n",
    "df['rooms_total'] = df['bedrooms'] + df['bathrooms']\n",
    "df['area_per_room'] = df['area'] / df['rooms_total']\n",
    "df['bathroom_bedroom_ratio'] = df['bathrooms'] / df['bedrooms']\n",
    "\n",
    "print(\"✅ Variables dérivées de base créées:\")\n",
    "print(\"   • price_per_sqft: Prix par pied carré\")\n",
    "print(\"   • rooms_total: Nombre total de pièces\")\n",
    "print(\"   • area_per_room: Surface par pièce\")\n",
    "print(\"   • bathroom_bedroom_ratio: Ratio SdB/Chambres\")\n",
    "\n",
    "# 2. Variables d'équipements combinées\n",
    "luxury_features = ['guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea']\n",
    "df['luxury_score'] = df[luxury_features].sum(axis=1)\n",
    "df['has_luxury'] = (df['luxury_score'] > 0).astype(int)\n",
    "\n",
    "print(\"\\n✅ Variables d'équipements créées:\")\n",
    "print(\"   • luxury_score: Score d'équipements de luxe (0-5)\")\n",
    "print(\"   • has_luxury: Présence d'au moins un équipement de luxe\")\n",
    "\n",
    "# 3. Catégorisation des tailles\n",
    "def categorize_size(area):\n",
    "    if area <= 5000:\n",
    "        return 'small'\n",
    "    elif area <= 8000:\n",
    "        return 'medium'\n",
    "    elif area <= 12000:\n",
    "        return 'large'\n",
    "    else:\n",
    "        return 'very_large'\n",
    "\n",
    "def categorize_price_range(price):\n",
    "    if price <= 4000000:\n",
    "        return 'budget'\n",
    "    elif price <= 6000000:\n",
    "        return 'mid_range'\n",
    "    elif price <= 10000000:\n",
    "        return 'premium'\n",
    "    else:\n",
    "        return 'luxury'\n",
    "\n",
    "df['size_category'] = df['area'].apply(categorize_size)\n",
    "df['price_category'] = df['price'].apply(categorize_price_range)\n",
    "\n",
    "print(\"\\n✅ Catégories créées:\")\n",
    "print(\"   • size_category: Catégorie de taille (small/medium/large/very_large)\")\n",
    "print(\"   • price_category: Gamme de prix (budget/mid_range/premium/luxury)\")\n",
    "\n",
    "# 4. Variables d'interaction importantes\n",
    "df['area_bedrooms_interaction'] = df['area'] * df['bedrooms']\n",
    "df['luxury_area_interaction'] = df['luxury_score'] * df['area']\n",
    "\n",
    "print(\"\\n✅ Variables d'interaction créées:\")\n",
    "print(\"   • area_bedrooms_interaction: Surface × Chambres\")\n",
    "print(\"   • luxury_area_interaction: Score luxe × Surface\")\n",
    "\n",
    "# 5. Aperçu des nouvelles variables\n",
    "new_features = ['price_per_sqft', 'rooms_total', 'area_per_room', 'bathroom_bedroom_ratio',\n",
    "                'luxury_score', 'has_luxury', 'size_category', 'price_category',\n",
    "                'area_bedrooms_interaction', 'luxury_area_interaction']\n",
    "\n",
    "print(f\"\\n📊 APERÇU DES NOUVELLES VARIABLES:\")\n",
    "for feature in new_features[:6]:  # Montrer les numériques d'abord\n",
    "    if df[feature].dtype in ['int64', 'float64']:\n",
    "        print(f\"   {feature:25s}: {df[feature].mean():8.1f} (±{df[feature].std():6.1f})\")\n",
    "\n",
    "print(f\"\\n📊 DISTRIBUTION DES CATÉGORIES:\")\n",
    "for feature in ['size_category', 'price_category']:\n",
    "    print(f\"   {feature}:\")\n",
    "    counts = df[feature].value_counts()\n",
    "    for cat, count in counts.items():\n",
    "        pct = count/len(df)*100\n",
    "        print(f\"     {cat:12s}: {count:3d} ({pct:4.1f}%)\")\n",
    "\n",
    "print(f\"\\n✅ Feature engineering terminé ! Total variables: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c807b3e",
   "metadata": {},
   "source": [
    "## 📊 Division des Données (Train/Validation/Test)\n",
    "\n",
    "Divisons nos données proprement pour l'entraînement et l'évaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66d1c25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 PRÉPARATION POUR LA DIVISION DES DONNÉES\n",
      "==================================================\n",
      "🎯 Variable cible: price\n",
      "📊 Features numériques: 20\n",
      "🏷️ Features catégorielles: 1\n",
      "📋 Total features: 21\n",
      "\n",
      "🔢 FEATURES NUMÉRIQUES:\n",
      "    1. area\n",
      "    2. bedrooms\n",
      "    3. bathrooms\n",
      "    4. stories\n",
      "    5. mainroad\n",
      "    6. guestroom\n",
      "    7. basement\n",
      "    8. hotwaterheating\n",
      "    9. airconditioning\n",
      "   10. parking\n",
      "   11. prefarea\n",
      "   12. furnishingstatus\n",
      "   13. price_per_sqft\n",
      "   14. rooms_total\n",
      "   15. area_per_room\n",
      "   16. bathroom_bedroom_ratio\n",
      "   17. luxury_score\n",
      "   18. has_luxury\n",
      "   19. area_bedrooms_interaction\n",
      "   20. luxury_area_interaction\n",
      "\n",
      "🏷️ FEATURES CATÉGORIELLES:\n",
      "    1. size_category\n",
      "       Valeurs: ['medium', 'large', 'very_large', 'small']\n",
      "\n",
      "🔄 ENCODAGE ONE-HOT:\n",
      "   ✅ size_category: 3 nouvelles variables\n",
      "\n",
      "📊 DATASET FINAL POUR LA MODÉLISATION:\n",
      "   Shape X: (545, 23)\n",
      "   Shape y: (545,)\n",
      "   Total features après encodage: 23\n"
     ]
    }
   ],
   "source": [
    "# 1. Préparation des variables pour la modélisation\n",
    "print(\"📊 PRÉPARATION POUR LA DIVISION DES DONNÉES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Variables cibles\n",
    "target = 'price'\n",
    "y = df[target].copy()\n",
    "\n",
    "# Sélection des variables prédictives\n",
    "# Exclure la cible et les catégories dérivées de la cible\n",
    "features_to_exclude = [target, 'price_category']\n",
    "feature_columns = [col for col in df.columns if col not in features_to_exclude]\n",
    "\n",
    "# Séparer les variables numériques et catégorielles\n",
    "numeric_features = df[feature_columns].select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_features = df[feature_columns].select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"🎯 Variable cible: {target}\")\n",
    "print(f\"📊 Features numériques: {len(numeric_features)}\")\n",
    "print(f\"🏷️ Features catégorielles: {len(categorical_features)}\")\n",
    "print(f\"📋 Total features: {len(numeric_features) + len(categorical_features)}\")\n",
    "\n",
    "print(f\"\\n🔢 FEATURES NUMÉRIQUES:\")\n",
    "for i, feat in enumerate(numeric_features, 1):\n",
    "    print(f\"   {i:2d}. {feat}\")\n",
    "\n",
    "if categorical_features:\n",
    "    print(f\"\\n🏷️ FEATURES CATÉGORIELLES:\")\n",
    "    for i, feat in enumerate(categorical_features, 1):\n",
    "        print(f\"   {i:2d}. {feat}\")\n",
    "        unique_values = df[feat].unique()\n",
    "        print(f\"       Valeurs: {list(unique_values)}\")\n",
    "\n",
    "# Préparer X (features) avec encodage des variables catégorielles\n",
    "X = df[numeric_features].copy()\n",
    "\n",
    "# One-hot encoding pour les variables catégorielles\n",
    "if categorical_features:\n",
    "    print(f\"\\n🔄 ENCODAGE ONE-HOT:\")\n",
    "    for feat in categorical_features:\n",
    "        # One-hot encoding\n",
    "        dummies = pd.get_dummies(df[feat], prefix=feat, drop_first=True)\n",
    "        X = pd.concat([X, dummies], axis=1)\n",
    "        print(f\"   ✅ {feat}: {len(dummies.columns)} nouvelles variables\")\n",
    "\n",
    "print(f\"\\n📊 DATASET FINAL POUR LA MODÉLISATION:\")\n",
    "print(f\"   Shape X: {X.shape}\")\n",
    "print(f\"   Shape y: {y.shape}\")\n",
    "print(f\"   Total features après encodage: {X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd3c12fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✂️ DIVISION DES DONNÉES\n",
      "==============================\n",
      "📊 Stratification basée sur les quartiles de prix:\n",
      "price\n",
      "Q1    137\n",
      "Q2    138\n",
      "Q3    134\n",
      "Q4    136\n",
      "Name: count, dtype: int64\n",
      "\n",
      "📊 RÉPARTITION DES DONNÉES:\n",
      "   🏋️ Train: 327 échantillons (60.0%)\n",
      "   ✅ Validation: 109 échantillons (20.0%)\n",
      "   🧪 Test: 109 échantillons (20.0%)\n",
      "   📊 Total: 545 échantillons\n",
      "\n",
      "💰 RÉPARTITION DES PRIX PAR ENSEMBLE:\n",
      "   Train     : 4,739,763 (±1,754,574) [1,870,400 - 10,542,000]\n",
      "   Validation: 4,815,660 (±1,973,180) [1,870,400 - 10,542,000]\n",
      "   Test      : 4,720,782 (±1,810,334) [1,870,400 - 10,150,000]\n",
      "\n",
      "✅ Division des données terminée !\n",
      "📊 Features: 23\n",
      "🎯 Prêt pour la normalisation et la modélisation\n"
     ]
    }
   ],
   "source": [
    "# 2. Division stratifiée des données\n",
    "print(\"✂️ DIVISION DES DONNÉES\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Créer des strates basées sur les prix pour assurer une répartition équilibrée\n",
    "price_bins = pd.qcut(y, q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'])\n",
    "print(\"📊 Stratification basée sur les quartiles de prix:\")\n",
    "print(price_bins.value_counts().sort_index())\n",
    "\n",
    "# Division principale: 80% train+val, 20% test\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=price_bins\n",
    ")\n",
    "\n",
    "# Recréer les strates pour les données temporaires\n",
    "price_bins_temp = pd.qcut(y_temp, q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'])\n",
    "\n",
    "# Division train/validation: 75% train, 25% validation du reste\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    test_size=0.25,  # 25% de 80% = 20% du total\n",
    "    random_state=42,\n",
    "    stratify=price_bins_temp\n",
    ")\n",
    "\n",
    "# Résumé des divisions\n",
    "print(f\"\\n📊 RÉPARTITION DES DONNÉES:\")\n",
    "print(f\"   🏋️ Train: {X_train.shape[0]:3d} échantillons ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"   ✅ Validation: {X_val.shape[0]:3d} échantillons ({X_val.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"   🧪 Test: {X_test.shape[0]:3d} échantillons ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"   📊 Total: {len(X):3d} échantillons\")\n",
    "\n",
    "# Vérification de la répartition des prix dans chaque ensemble\n",
    "print(f\"\\n💰 RÉPARTITION DES PRIX PAR ENSEMBLE:\")\n",
    "sets_info = {\n",
    "    'Train': y_train,\n",
    "    'Validation': y_val,\n",
    "    'Test': y_test\n",
    "}\n",
    "\n",
    "for set_name, y_set in sets_info.items():\n",
    "    print(f\"   {set_name:10s}: {y_set.mean():8,.0f} (±{y_set.std():8,.0f}) [{y_set.min():7,.0f} - {y_set.max():8,.0f}]\")\n",
    "\n",
    "print(f\"\\n✅ Division des données terminée !\")\n",
    "print(f\"📊 Features: {X_train.shape[1]}\")\n",
    "print(f\"🎯 Prêt pour la normalisation et la modélisation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabacf77",
   "metadata": {},
   "source": [
    "## 🔄 Normalisation des Données\n",
    "\n",
    "Normalisons les données pour optimiser les performances des algorithmes de machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65305346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 NORMALISATION DES DONNÉES\n",
      "===================================\n",
      "🧪 COMPARAISON DES MÉTHODES DE NORMALISATION:\n",
      "\n",
      "📊 Variable exemple: price_per_sqft\n",
      "   Original: 1000.6 (±346.7)\n",
      "   StandardScaler: 0.000 (±1.000)\n",
      "   MinMaxScaler : 0.294 (±0.149)\n",
      "   RobustScaler : 0.112 (±0.822)\n",
      "\n",
      "⚙️ APPLICATION DE LA NORMALISATION:\n",
      "✅ RobustScaler appliqué à tous les ensembles\n",
      "   Train normalisé: (327, 23)\n",
      "   Validation normalisé: (109, 23)\n",
      "   Test normalisé: (109, 23)\n",
      "\n",
      "📊 VÉRIFICATION DE LA NORMALISATION:\n",
      "   Variables avec moyenne ~0 et std ~1: 5/23\n",
      "\n",
      "📈 STATISTIQUES APRÈS NORMALISATION (Train):\n",
      "   area                     :  0.215 (±0.751)\n",
      "   bedrooms                 : -0.046 (±0.735)\n",
      "   bathrooms                :  0.284 (±0.515)\n",
      "   stories                  : -0.220 (±0.847)\n",
      "   mainroad                 : -0.159 (±0.366)\n",
      "\n",
      "✅ Normalisation terminée !\n",
      "📊 Données prêtes pour la modélisation\n",
      "✅ RobustScaler appliqué à tous les ensembles\n",
      "   Train normalisé: (327, 23)\n",
      "   Validation normalisé: (109, 23)\n",
      "   Test normalisé: (109, 23)\n",
      "\n",
      "📊 VÉRIFICATION DE LA NORMALISATION:\n",
      "   Variables avec moyenne ~0 et std ~1: 5/23\n",
      "\n",
      "📈 STATISTIQUES APRÈS NORMALISATION (Train):\n",
      "   area                     :  0.215 (±0.751)\n",
      "   bedrooms                 : -0.046 (±0.735)\n",
      "   bathrooms                :  0.284 (±0.515)\n",
      "   stories                  : -0.220 (±0.847)\n",
      "   mainroad                 : -0.159 (±0.366)\n",
      "\n",
      "✅ Normalisation terminée !\n",
      "📊 Données prêtes pour la modélisation\n"
     ]
    }
   ],
   "source": [
    "# 1. Comparaison des méthodes de normalisation\n",
    "print(\"🔄 NORMALISATION DES DONNÉES\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Tester différentes méthodes de normalisation sur un échantillon\n",
    "scalers = {\n",
    "    'StandardScaler': StandardScaler(),\n",
    "    'MinMaxScaler': MinMaxScaler(),\n",
    "    'RobustScaler': RobustScaler()\n",
    "}\n",
    "\n",
    "print(\"🧪 COMPARAISON DES MÉTHODES DE NORMALISATION:\")\n",
    "sample_feature = 'price_per_sqft'\n",
    "\n",
    "if sample_feature in X_train.columns:\n",
    "    original_data = X_train[sample_feature]\n",
    "    print(f\"\\n📊 Variable exemple: {sample_feature}\")\n",
    "    print(f\"   Original: {original_data.mean():.1f} (±{original_data.std():.1f})\")\n",
    "    \n",
    "    for name, scaler in scalers.items():\n",
    "        # Normaliser la variable exemple\n",
    "        transformed = scaler.fit_transform(original_data.values.reshape(-1, 1)).flatten()\n",
    "        print(f\"   {name:13s}: {transformed.mean():.3f} (±{transformed.std():.3f})\")\n",
    "\n",
    "# 2. Sélection et application de la méthode de normalisation\n",
    "print(f\"\\n⚙️ APPLICATION DE LA NORMALISATION:\")\n",
    "\n",
    "# Utiliser RobustScaler car il est moins sensible aux outliers\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# Normaliser les données d'entraînement\n",
    "X_train_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(X_train),\n",
    "    columns=X_train.columns,\n",
    "    index=X_train.index\n",
    ")\n",
    "\n",
    "# Normaliser les données de validation et test avec le même scaler\n",
    "X_val_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_val),\n",
    "    columns=X_val.columns,\n",
    "    index=X_val.index\n",
    ")\n",
    "\n",
    "X_test_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_test),\n",
    "    columns=X_test.columns,\n",
    "    index=X_test.index\n",
    ")\n",
    "\n",
    "print(f\"✅ RobustScaler appliqué à tous les ensembles\")\n",
    "print(f\"   Train normalisé: {X_train_scaled.shape}\")\n",
    "print(f\"   Validation normalisé: {X_val_scaled.shape}\")\n",
    "print(f\"   Test normalisé: {X_test_scaled.shape}\")\n",
    "\n",
    "# 3. Vérification de la normalisation\n",
    "print(f\"\\n📊 VÉRIFICATION DE LA NORMALISATION:\")\n",
    "print(f\"   Variables avec moyenne ~0 et std ~1: {(abs(X_train_scaled.mean()) < 0.1).sum()}/{X_train_scaled.shape[1]}\")\n",
    "\n",
    "# Montrer quelques statistiques\n",
    "print(f\"\\n📈 STATISTIQUES APRÈS NORMALISATION (Train):\")\n",
    "stats_sample = X_train_scaled.iloc[:, :5]  # Premières 5 variables\n",
    "for col in stats_sample.columns:\n",
    "    mean_val = stats_sample[col].mean()\n",
    "    std_val = stats_sample[col].std()\n",
    "    print(f\"   {col:25s}: {mean_val:6.3f} (±{std_val:5.3f})\")\n",
    "\n",
    "print(f\"\\n✅ Normalisation terminée !\")\n",
    "print(f\"📊 Données prêtes pour la modélisation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0720f0",
   "metadata": {},
   "source": [
    "## 💾 Sauvegarde des Données Préparées\n",
    "\n",
    "Sauvegardons toutes les données préparées pour la modélisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e8ff8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 SAUVEGARDE DES DONNÉES PRÉPARÉES\n",
      "========================================\n",
      "✅ Données brutes sauvegardées:\n",
      "   X_train_raw.csv: (327, 23)\n",
      "   X_val_raw.csv: (109, 23)\n",
      "   X_test_raw.csv: (109, 23)\n",
      "   y_train.csv, y_val.csv, y_test.csv\n",
      "\n",
      "✅ Données normalisées sauvegardées:\n",
      "   X_train_scaled.csv: (327, 23)\n",
      "   X_val_scaled.csv: (109, 23)\n",
      "   X_test_scaled.csv: (109, 23)\n",
      "\n",
      "✅ Dataset complet sauvegardé:\n",
      "   housing_final_cleaned.csv: (545, 23)\n",
      "\n",
      "✅ Métadonnées sauvegardées:\n",
      "   metadata.json\n",
      "\n",
      "🎯 RÉSUMÉ FINAL - ÉTAPE 2 TERMINÉE\n",
      "=============================================\n",
      "✅ Données nettoyées: 545 propriétés\n",
      "✅ Features créées: 23 variables\n",
      "✅ Outliers traités intelligemment\n",
      "✅ Données divisées (train/val/test)\n",
      "✅ Données normalisées avec RobustScaler\n",
      "✅ Tout sauvegardé dans ..\\data\\processed\n",
      "\n",
      "🚀 PROCHAINE ÉTAPE:\n",
      "   Étape 3 - Modélisation et évaluation\n",
      "   📊 327 échantillons d'entraînement prêts\n",
      "   🎯 23 features pour prédire les prix immobiliers\n"
     ]
    }
   ],
   "source": [
    "# 1. Sauvegarde des datasets\n",
    "print(\"💾 SAUVEGARDE DES DONNÉES PRÉPARÉES\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Créer le dossier de sauvegarde\n",
    "save_path = Path('../data/processed')\n",
    "save_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Sauvegarder les données non normalisées\n",
    "X_train.to_csv(save_path / 'X_train_raw.csv', index=False)\n",
    "X_val.to_csv(save_path / 'X_val_raw.csv', index=False)\n",
    "X_test.to_csv(save_path / 'X_test_raw.csv', index=False)\n",
    "\n",
    "y_train.to_csv(save_path / 'y_train.csv', index=False)\n",
    "y_val.to_csv(save_path / 'y_val.csv', index=False)\n",
    "y_test.to_csv(save_path / 'y_test.csv', index=False)\n",
    "\n",
    "print(\"✅ Données brutes sauvegardées:\")\n",
    "print(f\"   X_train_raw.csv: {X_train.shape}\")\n",
    "print(f\"   X_val_raw.csv: {X_val.shape}\")\n",
    "print(f\"   X_test_raw.csv: {X_test.shape}\")\n",
    "print(f\"   y_train.csv, y_val.csv, y_test.csv\")\n",
    "\n",
    "# Sauvegarder les données normalisées\n",
    "X_train_scaled.to_csv(save_path / 'X_train_scaled.csv', index=False)\n",
    "X_val_scaled.to_csv(save_path / 'X_val_scaled.csv', index=False)\n",
    "X_test_scaled.to_csv(save_path / 'X_test_scaled.csv', index=False)\n",
    "\n",
    "print(\"\\n✅ Données normalisées sauvegardées:\")\n",
    "print(f\"   X_train_scaled.csv: {X_train_scaled.shape}\")\n",
    "print(f\"   X_val_scaled.csv: {X_val_scaled.shape}\")\n",
    "print(f\"   X_test_scaled.csv: {X_test_scaled.shape}\")\n",
    "\n",
    "# Sauvegarder le dataset complet avec les nouvelles features\n",
    "df.to_csv(save_path / 'housing_final_cleaned.csv', index=False)\n",
    "print(f\"\\n✅ Dataset complet sauvegardé:\")\n",
    "print(f\"   housing_final_cleaned.csv: {df.shape}\")\n",
    "\n",
    "# Sauvegarder les métadonnées importantes\n",
    "metadata = {\n",
    "    'dataset_info': {\n",
    "        'total_samples': len(df),\n",
    "        'total_features': X_train.shape[1],\n",
    "        'train_samples': X_train.shape[0],\n",
    "        'val_samples': X_val.shape[0],\n",
    "        'test_samples': X_test.shape[0]\n",
    "    },\n",
    "    'features': {\n",
    "        'numeric_features': numeric_features,\n",
    "        'categorical_features': categorical_features,\n",
    "        'all_features': list(X_train.columns)\n",
    "    },\n",
    "    'target': target,\n",
    "    'scaler_used': 'RobustScaler'\n",
    "}\n",
    "\n",
    "import json\n",
    "with open(save_path / 'metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\n✅ Métadonnées sauvegardées:\")\n",
    "print(f\"   metadata.json\")\n",
    "\n",
    "# 2. Résumé final\n",
    "print(f\"\\n🎯 RÉSUMÉ FINAL - ÉTAPE 2 TERMINÉE\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"✅ Données nettoyées: {len(df)} propriétés\")\n",
    "print(f\"✅ Features créées: {X_train.shape[1]} variables\")\n",
    "print(f\"✅ Outliers traités intelligemment\")\n",
    "print(f\"✅ Données divisées (train/val/test)\")\n",
    "print(f\"✅ Données normalisées avec RobustScaler\")\n",
    "print(f\"✅ Tout sauvegardé dans {save_path}\")\n",
    "\n",
    "print(f\"\\n🚀 PROCHAINE ÉTAPE:\")\n",
    "print(f\"   Étape 3 - Modélisation et évaluation\")\n",
    "print(f\"   📊 {X_train.shape[0]} échantillons d'entraînement prêts\")\n",
    "print(f\"   🎯 {X_train.shape[1]} features pour prédire les prix immobiliers\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
